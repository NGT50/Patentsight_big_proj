
import os
import json
from typing import Any, Dict, List, Optional, TypedDict

import httpx
from fastapi import FastAPI
from fastapi.responses import PlainTextResponse
from pydantic import BaseModel
from dotenv import load_dotenv
from langgraph.graph import StateGraph, START, END

# =========================
# í™˜ê²½ì„¤ì •
# =========================
load_dotenv()
# ì‹¤ì œ AI ëª¨ë¸ ì„œë²„ ì£¼ì†Œë“¤
VALIDATE_URL = "http://3.26.101.212:8000/api/ai/validations"  # í˜•ì‹/ë¬¸ë§¥ ì˜¤ë¥˜ íƒì§€
CLAIM_DRAFT_URL = "http://3.26.101.212:8000/generate"         # ì²­êµ¬í•­ ì´ˆì•ˆ ìƒì„±
ANALYZE_URL = "http://13.236.174.54:8000/analyze"             # ìœ ì‚¬ íŠ¹í—ˆ + ê±°ì ˆì‚¬ìœ  ë¶„ì„

# â˜… ì—¬ê¸° ìˆ˜ì •: httpx.Timeoutì€ 4ê°œ íŒŒë¼ë¯¸í„°(connect/read/write/pool) ëª¨ë‘ ì§€ì • í•„ìš”
TIMEOUT = httpx.Timeout(connect=20.0, read=60.0, write=20.0, pool=20.0)
HEADERS = {"Content-Type": "application/json"}

# =========================
# HTTP ìœ í‹¸
# =========================
async def http_post(url: str, payload: Dict[str, Any]) -> Dict[str, Any]:
    async with httpx.AsyncClient(timeout=TIMEOUT, headers=HEADERS) as c:
        r = await c.post(url, json=payload)
        r.raise_for_status()
        return r.json()

async def http_get(url: str, params: Dict[str, Any]) -> Dict[str, Any]:
    async with httpx.AsyncClient(timeout=TIMEOUT, headers=HEADERS) as c:
        r = await c.get(url, params=params)
        r.raise_for_status()
        return r.json()

# =========================
# ìš”ì²­/ìƒíƒœ ìŠ¤í‚¤ë§ˆ
# =========================
class ChatRequest(BaseModel):
    session_id: str
    user_msg: str
    application_text: str = ""
    claims_text: str = ""
    forced_intent: Optional[str] = None  # "validate_doc" ë“± ê°•ì œ

class BotState(TypedDict, total=False):
    # ì…ë ¥/ë§¥ë½
    user_msg: str
    application_text: str
    claims_text: str
    forced_intent: Optional[str]

    # ì˜ë„/ê²°ê³¼
    intent: Optional[str]
    results: Dict[str, Any]
    final_answer: str

    # ëŒ€í™” íˆìŠ¤í† ë¦¬
    history: List[Dict[str, str]]

def new_state() -> BotState:
    return {
        "user_msg": "",
        "application_text": "",
        "claims_text": "",
        "forced_intent": None,
        "intent": None,
        "results": {},
        "final_answer": "",
        "history": [],
    }

# =========================
# ë¶„ë¥˜ ë…¸ë“œ (ê·œì¹™ ìš°ì„ , í•œê¸€ í‚¤ì›Œë“œ ê°•í™”)
# =========================
VALIDATE_KEYWORDS = [
    "ë¬¸ì œì ", "ë¬¸ì œ", "ì˜¤ë¥˜", "ì—ëŸ¬", "ê²€í† ", "í™•ì¸", "ì²´í¬", "ì ê²€",
    "ìœ íš¨ì„±", "validation", "validate", "í˜•ì‹", "ë¬¸ë§¥", "ëˆ„ë½", "ì˜¤íƒˆì"
]
SIMILAR_KEYWORDS = ["ìœ ì‚¬", "ì„ í–‰", "ê²€ìƒ‰", "ë¹„ìŠ·í•œ", "ê°™ì€", "ì°¸ê³ "]
CLAIM_KEYWORDS = ["ì²­êµ¬í•­", "ì´ˆì•ˆ", "ìƒì„±", "ì‘ì„±", "claim", "draft"]
REJECTION_KEYWORDS = ["ê±°ì ˆ", "í†µì§€", "ê±°ë¶€", "rejection", "reject"]

async def node_classify(s: BotState) -> BotState:
    forced = s.get("forced_intent")
    if forced:
        s["intent"] = forced
        return s

    m = s.get("user_msg", "") or ""
    print(f"ğŸ” ë¶„ë¥˜ ì¤‘: '{m}'")

    if any(k in m for k in VALIDATE_KEYWORDS):
        s["intent"] = "validate_doc"
        print("âœ… validate_docë¡œ ë¶„ë¥˜ë¨")
    elif any(k in m for k in SIMILAR_KEYWORDS):
        s["intent"] = "similar_patent"
        print("âœ… similar_patentë¡œ ë¶„ë¥˜ë¨")
    elif any(k in m for k in CLAIM_KEYWORDS):
        s["intent"] = "claim_draft"
        print("âœ… claim_draftë¡œ ë¶„ë¥˜ë¨")
    elif any(k in m for k in REJECTION_KEYWORDS):
        s["intent"] = "rejection_draft"
        print("âœ… rejection_draftë¡œ ë¶„ë¥˜ë¨")
    else:
        s["intent"] = "small_talk"
        print("âœ… small_talkë¡œ ë¶„ë¥˜ë¨")
    return s

# =========================
# analyze í˜ì´ë¡œë“œ í—¬í¼ (main.pyì˜ extract_text_from_json ê¸°ëŒ€ ìŠ¤í‚¤ë§ˆ)
# =========================
def build_analyze_payload(s: BotState) -> Dict[str, Any]:
    app_text = (s.get("application_text") or "").strip()
    claims_text = (s.get("claims_text") or "").strip()
    return {
        "title": "ì¶œì›ë¬¸ ìë™ ë¶„ì„",
        "summary": (s.get("user_msg") or "").strip(),
        "applicationContent": app_text,
        "claims": (
            [{"claimNumber": 1, "claimType": "independent", "claimText": claims_text}]
            if claims_text else []
        ),
        # í•„ìš” ì‹œ technicalField, backgroundTechnology ë“± í™•ì¥ ê°€ëŠ¥
    }

# =========================
# ê¸°ëŠ¥ ë…¸ë“œ
# =========================
async def node_validate(s: BotState) -> BotState:
    payload = {
        "title": "ì¸ê³µì§€ëŠ¥ íŠ¹í—ˆ ê²€ìƒ‰ ì‹œìŠ¤í…œ",
        "technicalField": "ì¸ê³µì§€ëŠ¥, íŠ¹í—ˆ ê²€ìƒ‰",
        "backgroundTechnology": "ê¸°ì¡´ ìˆ˜ë™ ê²€ìƒ‰ ë°©ì‹ì˜ í•œê³„",
        "claims": [s.get("claims_text","")] if s.get("claims_text") else [],
        "inventionDetails": {
            "problemToSolve": "ìˆ˜ë™ ê²€ìƒ‰ì˜ ë¹„íš¨ìœ¨ì„±",
            "solution": "AI ê¸°ë°˜ ìë™ ê²€ìƒ‰",
            "effect": "ê²€ìƒ‰ íš¨ìœ¨ì„± í–¥ìƒ"
        },
        "application_text": s.get("application_text",""),
    }
    try:
        result = await http_post(VALIDATE_URL, payload)
        print(f"ğŸ” AI ëª¨ë¸ ì‘ë‹µ(ê²€ì¦): {json.dumps(result, ensure_ascii=False)[:1000]}")
    except Exception as e:
        result = {"error": f"validation call failed: {e}"}
        print(f"âŒ AI ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨(ê²€ì¦): {e}")

    s.setdefault("results", {})["validate_doc"] = result
    return s

async def node_similar_patent(s: BotState) -> BotState:
    payload = build_analyze_payload(s)
    try:
        full_result = await http_post(ANALYZE_URL, payload)
        print(f"âœ… analyze í˜¸ì¶œ ì„±ê³µ: keys={list(full_result.keys())}")
        # main.pyëŠ” "similar_patents" í‚¤ë¡œ ë°˜í™˜
        if "similar_patents" in full_result:
            result = {
                "patents": full_result["similar_patents"],
                "extracted_from": "analyze_endpoint"
            }
        else:
            # êµ¬ì¡°ê°€ ë‹¬ë¼ë„ ì›ë³¸ì„ ê·¸ëŒ€ë¡œ ë³´ê´€
            result = full_result
    except Exception as e:
        result = {"error": f"similar search failed: {e}"}
        print(f"âŒ analyze í˜¸ì¶œ ì‹¤íŒ¨(ìœ ì‚¬íŠ¹í—ˆ): {e}")

    s.setdefault("results", {})["similar_patent"] = result
    return s

async def node_claim_draft(s: BotState) -> BotState:
    payload = {
        "query": s.get("user_msg") or "ë°œëª… ìš”ì•½",
        "top_k": 5
    }
    try:
        result = await http_post(CLAIM_DRAFT_URL, payload)
    except Exception as e:
        result = {"error": f"claim draft failed: {e}"}
    s.setdefault("results", {})["claim_draft"] = result
    return s

async def node_rejection_draft(s: BotState) -> BotState:
    # 1) ìœ ì‚¬ íŠ¹í—ˆ (analyze)
    try:
        similar_patents_result = await http_post(ANALYZE_URL, build_analyze_payload(s))
        print(f"âœ… analyze í˜¸ì¶œ ì„±ê³µ(ê±°ì ˆì‚¬ìœ ): keys={list(similar_patents_result.keys())}")
    except Exception as e:
        similar_patents_result = {"error": f"similar search failed: {e}"}
        print(f"âŒ analyze í˜¸ì¶œ ì‹¤íŒ¨(ê±°ì ˆì‚¬ìœ ): {e}")

    # 2) í˜•ì‹/ë¬¸ë§¥ ê²€ì¦
    try:
        validation_payload = {
            "title": "ì¸ê³µì§€ëŠ¥ íŠ¹í—ˆ ê²€ìƒ‰ ì‹œìŠ¤í…œ",
            "technicalField": "ì¸ê³µì§€ëŠ¥, íŠ¹í—ˆ ê²€ìƒ‰",
            "backgroundTechnology": "ê¸°ì¡´ ìˆ˜ë™ ê²€ìƒ‰ ë°©ì‹ì˜ í•œê³„",
            "claims": [s.get("claims_text","")] if s.get("claims_text") else [],
            "inventionDetails": {
                "problemToSolve": "ìˆ˜ë™ ê²€ìƒ‰ì˜ ë¹„íš¨ìœ¨ì„±",
                "solution": "AI ê¸°ë°˜ ìë™ ê²€ìƒ‰",
                "effect": "ê²€ìƒ‰ íš¨ìœ¨ì„± í–¥ìƒ"
            },
            "application_text": s.get("application_text",""),
        }
        validation_result = await http_post(VALIDATE_URL, validation_payload)
        print(f"ğŸ” í˜•ì‹/ë¬¸ë§¥ ê²€ì‚¬ ê²°ê³¼: {json.dumps(validation_result, ensure_ascii=False)[:1000]}")
    except Exception as e:
        validation_result = {"error": f"validation failed: {e}"}
        print(f"âŒ í˜•ì‹/ë¬¸ë§¥ ê²€ì‚¬ ì‹¤íŒ¨: {e}")

    combined_result = {
        "similar_patents": similar_patents_result,
        "validation_errors": validation_result,
        "combined_analysis": {
            "timestamp": __import__("datetime").datetime.utcnow().isoformat() + "Z",
            "analysis_type": "comprehensive_rejection_analysis"
        }
    }
    s.setdefault("results", {})["rejection_draft"] = combined_result
    return s

async def node_small_talk(s: BotState) -> BotState:
    s["final_answer"] = "ì•ˆë…•í•˜ì„¸ìš”! íŠ¹í—ˆ ë¬¸ì„œ ì ê²€, ìœ ì‚¬íŠ¹í—ˆ ê²€ìƒ‰, ì²­êµ¬í•­ ì´ˆì•ˆ, ê±°ì ˆ ì‚¬ìœ  ì´ˆì•ˆ ì¤‘ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    return s

# =========================
# ê²°ê³¼ í•©ì„±
# =========================
def summarize_validate(result: Dict[str, Any]) -> str:
    if "error" in result:
        return f"âš ï¸ ì ê²€ API í˜¸ì¶œ ì˜¤ë¥˜: {result['error']}"
    lines = ["[ë¬¸ì„œ ì ê²€ ê²°ê³¼]", "ì›ë³¸ AI ëª¨ë¸ ì‘ë‹µ:", json.dumps(result, ensure_ascii=False, indent=2), "\n[ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½]"]
    fmt = result.get("formatErrors") or []
    ctx = result.get("contextualErrors") or []
    miss = result.get("missingSections") or []
    if not fmt and not ctx and not miss:
        lines.append("â€¢ ëšœë ·í•œ í˜•ì‹/ë¬¸ë§¥ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    else:
        if fmt:
            lines.append("â€¢ í˜•ì‹ ì˜¤ë¥˜:")
            for e in fmt:
                lines.append(f"  - ({e.get('severity','')}) {e.get('message','')}")
        if ctx:
            lines.append("â€¢ ë¬¸ë§¥/ë‚´ìš© ì˜¤ë¥˜:")
            for e in ctx:
                lines.append(f"  - {e.get('analysis','') or e.get('message','')}")
        if miss:
            lines.append("â€¢ ëˆ„ë½ëœ ì„¹ì…˜:")
            for e in miss:
                lines.append(f"  - {e.get('message','') or e.get('field','')}")
    lines.append("\në‹¤ìŒ ì•¡ì…˜ ì œì•ˆ: 1) ë¬¸ì œ ë¬¸êµ¬/ì„¹ì…˜ ë³´ì™„  2) ìœ ì‚¬íŠ¹í—ˆ ê²€ìƒ‰ìœ¼ë¡œ ì°¨ë³„ì  í™•ì¸  3) ë³´ì™„ í›„ ì¬ì ê²€")
    return "\n".join(lines)

def summarize_similar(result: Dict[str, Any]) -> str:
    if "error" in result:
        return f"âš ï¸ ìœ ì‚¬ íŠ¹í—ˆ ê²€ìƒ‰ ì˜¤ë¥˜: {result['error']}"
    lines = ["[ìœ ì‚¬ íŠ¹í—ˆ ê²€ìƒ‰ ê²°ê³¼]", "ì›ë³¸ AI ëª¨ë¸ ì‘ë‹µ:", json.dumps(result, ensure_ascii=False, indent=2), "\n[ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½]"]
    patents = result.get("patents") or []
    if not patents:
        lines.append("â€¢ ìœ ì‚¬í•œ íŠ¹í—ˆë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        lines.append(f"â€¢ ë°œê²¬ëœ ìœ ì‚¬ íŠ¹í—ˆ {len(patents)}ê°œ:")
        for i, patent in enumerate(patents[:5], 1):
            lines.append(f"  - {i}. {patent.get('title', 'ì œëª© ì—†ìŒ')}")
            lines.append(f"    ìœ ì‚¬ë„: {patent.get('similarity', patent.get('score', 'N/A'))}")
            if patent.get('abstract'):
                lines.append(f"    ìš”ì•½: {patent.get('abstract', '')[:100]}...")
    return "\n".join(lines)

def summarize_claim_draft(result: Dict[str, Any]) -> str:
    if "error" in result:
        return f"âš ï¸ ì²­êµ¬í•­ ì´ˆì•ˆ ìƒì„± ì˜¤ë¥˜: {result['error']}"
    claims = result.get("claims") or []
    lines = ["[ì²­êµ¬í•­ ì´ˆì•ˆ ìƒì„± ê²°ê³¼]"]
    if not claims:
        lines.append("â€¢ ì²­êµ¬í•­ ì´ˆì•ˆì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        for i, claim in enumerate(claims, 1):
            lines.append(f"â€¢ ì²­êµ¬í•­ {i}: {claim}")
    return "\n".join(lines)

def summarize_rejection(result: Dict[str, Any]) -> str:
    if "error" in result:
        return f"âš ï¸ ê±°ì ˆì‚¬ìœ  ì¢…í•© ë¶„ì„ ì˜¤ë¥˜: {result['error']}"
    lines = ["[ê±°ì ˆì‚¬ìœ  ì¢…í•© ë¶„ì„ ê²°ê³¼]", "ì›ë³¸ AI ëª¨ë¸ ì‘ë‹µ:", json.dumps(result, ensure_ascii=False, indent=2), "\n[ì‚¬ìš©ì ì¹œí™”ì  ìš”ì•½]"]
    similar_patents = result.get("similar_patents", {})
    if "error" in similar_patents:
        lines.append("â€¢ ìœ ì‚¬ íŠ¹í—ˆ ê²€ìƒ‰ ì‹¤íŒ¨")
    else:
        patents = similar_patents.get("patents") or similar_patents.get("similar_patents") or []
        if patents:
            lines.append("â€¢ ë°œê²¬ëœ ìœ ì‚¬ íŠ¹í—ˆ:")
            for i, patent in enumerate(patents[:3], 1):
                score = patent.get('similarity', patent.get('score', 'N/A'))
                lines.append(f"  - {i}. {patent.get('title', 'ì œëª© ì—†ìŒ')} (ìœ ì‚¬ë„: {score})")
        else:
            lines.append("â€¢ ìœ ì‚¬í•œ íŠ¹í—ˆë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    validation_errors = result.get("validation_errors", {})
    if "error" in validation_errors:
        lines.append("â€¢ í˜•ì‹/ë¬¸ë§¥ ì˜¤ë¥˜ ê²€ì‚¬ ì‹¤íŒ¨")
    else:
        fmt_errors = validation_errors.get("formatErrors") or []
        ctx_errors = validation_errors.get("contextualErrors") or []
        miss_sections = validation_errors.get("missingSections") or []
        if fmt_errors or ctx_errors or miss_sections:
            lines.append("â€¢ ë°œê²¬ëœ ë¬¸ì„œ ì˜¤ë¥˜:")
            if fmt_errors:
                lines.append("  - í˜•ì‹ ì˜¤ë¥˜:")
                for e in fmt_errors[:3]:
                    lines.append(f"    * {e.get('message', '')}")
            if ctx_errors:
                lines.append("  - ë¬¸ë§¥ ì˜¤ë¥˜:")
                for e in ctx_errors[:3]:
                    lines.append(f"    * {e.get('analysis', '') or e.get('message', '')}")
            if miss_sections:
                lines.append("  - ëˆ„ë½ëœ ì„¹ì…˜:")
                for e in miss_sections[:3]:
                    lines.append(f"    * {e.get('message', '')}")
        else:
            lines.append("â€¢ ëšœë ·í•œ ë¬¸ì„œ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    lines.append("\n[ì¢…í•© ê±°ì ˆì‚¬ìœ  ì œì•ˆ]")
    has_similar = similar_patents and "error" not in similar_patents and (similar_patents.get("patents") or similar_patents.get("similar_patents"))
    has_errors = validation_errors and "error" not in validation_errors and (
        validation_errors.get("formatErrors") or validation_errors.get("contextualErrors") or validation_errors.get("missingSections")
    )
    if has_similar and has_errors:
        lines.append("â€¢ ì„ í–‰ê¸°ìˆ ì— ì˜í•œ ê±°ì ˆ + ë¬¸ì„œ í˜•ì‹/ë¬¸ë§¥ ì˜¤ë¥˜")
    elif has_similar:
        lines.append("â€¢ ì„ í–‰ê¸°ìˆ ì— ì˜í•œ ê±°ì ˆ")
    elif has_errors:
        lines.append("â€¢ ë¬¸ì„œ í˜•ì‹/ë¬¸ë§¥ ì˜¤ë¥˜ë¡œ ì¸í•œ ê±°ì ˆ")
    else:
        lines.append("â€¢ í˜„ì¬ë¡œì„œëŠ” ëª…í™•í•œ ê±°ì ˆì‚¬ìœ ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return "\n".join(lines)

async def node_synthesize(s: BotState) -> BotState:
    intent = s.get("intent")
    resmap = s.get("results", {})
    if intent == "validate_doc":
        s["final_answer"] = summarize_validate(resmap.get("validate_doc", {}))
    elif intent == "similar_patent":
        s["final_answer"] = summarize_similar(resmap.get("similar_patent", {}))
    elif intent == "claim_draft":
        s["final_answer"] = summarize_claim_draft(resmap.get("claim_draft", {}))
    elif intent == "rejection_draft":
        s["final_answer"] = summarize_rejection(resmap.get("rejection_draft", {}))
    elif intent == "small_talk" and s.get("final_answer"):
        pass
    else:
        s["final_answer"] = "ìš”ì²­ì„ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."
    s.setdefault("history", []).append({"user": s.get("user_msg",""), "bot": s["final_answer"]})
    return s

# =========================
# LangGraph êµ¬ì„±
# =========================
graph = StateGraph(BotState)
graph.add_node("classify", node_classify)
graph.add_node("validate_doc", node_validate)
graph.add_node("similar_patent", node_similar_patent)
graph.add_node("claim_draft", node_claim_draft)
graph.add_node("rejection_draft", node_rejection_draft)
graph.add_node("small_talk", node_small_talk)
graph.add_node("synthesize", node_synthesize)

graph.add_edge(START, "classify")
graph.add_conditional_edges(
    "classify",
    lambda s: s.get("intent"),
    {
        "validate_doc": "validate_doc",
        "similar_patent": "similar_patent",
        "claim_draft": "claim_draft",
        "rejection_draft": "rejection_draft",
        "small_talk": "small_talk",
    },
)
graph.add_edge("validate_doc", "synthesize")
graph.add_edge("similar_patent", "synthesize")
graph.add_edge("claim_draft", "synthesize")
graph.add_edge("rejection_draft", "synthesize")
graph.add_edge("small_talk", "synthesize")
graph.add_edge("synthesize", END)

app_graph = graph.compile()

# =========================
# FastAPI
# =========================
app = FastAPI(title="LangGraph Patent Chatbot")

# CORS
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì¸ë©”ëª¨ë¦¬ ì„¸ì…˜ ì €ì¥
SESSIONS: Dict[str, BotState] = {}

@app.get("/health")
async def health():
    return {"ok": True, "validate_url": VALIDATE_URL is not None}

@app.post("/chat", response_class=PlainTextResponse)
async def chat(req: ChatRequest):
    """
    body:
    {
      "session_id": "u1",
      "user_msg": "...",
      "application_text": "...",
      "claims_text": "...",
      "forced_intent": "rejection_draft"  # ì˜µì…˜
    }
    """
    try:
        print(f"ğŸ“¨ ìš”ì²­ ë°›ìŒ: session_id={req.session_id}, user_msg='{req.user_msg}'")
        state: BotState = SESSIONS.get(req.session_id) or new_state()

        # ìµœì‹  ì…ë ¥ ë°˜ì˜
        state["user_msg"] = req.user_msg
        state["application_text"] = req.application_text
        state["claims_text"] = req.claims_text
        state["forced_intent"] = req.forced_intent

        # ê·¸ë˜í”„ ì‹¤í–‰
        final: BotState = await app_graph.ainvoke(state)

        # ì„¸ì…˜ ì €ì¥
        SESSIONS[req.session_id] = final

        answer = final.get("final_answer", "ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ’¬ ì‘ë‹µ: {answer[:200]}...")
        return answer
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {str(e)}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
