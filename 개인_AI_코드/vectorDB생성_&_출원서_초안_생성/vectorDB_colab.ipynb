{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "AIPlUBZN3G5g"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52cbe461a2c047e6a0337dac3467ab7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_747d43b8c97944479232478931a2b517",
              "IPY_MODEL_08523de636b0469b81f0637db0b12f5f",
              "IPY_MODEL_bc6c3d37068f45b28319f36dc30ca623"
            ],
            "layout": "IPY_MODEL_ddcc9d26baf2493f84d579ae563aa325"
          }
        },
        "747d43b8c97944479232478931a2b517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b22f831885402c8da4b415ef888682",
            "placeholder": "​",
            "style": "IPY_MODEL_337b7a399cf548d185200e8683be1ad0",
            "value": "config.json: 100%"
          }
        },
        "08523de636b0469b81f0637db0b12f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aa3f36f7bba4f45be59a606d83cd70b",
            "max": 467,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5d79e29b38e4b0e9e2a9371f3ca298e",
            "value": 467
          }
        },
        "bc6c3d37068f45b28319f36dc30ca623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b35abb33e9047459fe16152807fcb21",
            "placeholder": "​",
            "style": "IPY_MODEL_19279722eff84824acd7dc5cf552ab88",
            "value": " 467/467 [00:00&lt;00:00, 53.4kB/s]"
          }
        },
        "ddcc9d26baf2493f84d579ae563aa325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3b22f831885402c8da4b415ef888682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337b7a399cf548d185200e8683be1ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aa3f36f7bba4f45be59a606d83cd70b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5d79e29b38e4b0e9e2a9371f3ca298e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b35abb33e9047459fe16152807fcb21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19279722eff84824acd7dc5cf552ab88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42ffbbda982549b3b1e82249e534f08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e943840ec5e4332be182d4ae97e03e5",
              "IPY_MODEL_77a2b00b09da4a969660e7d9a67e0f02",
              "IPY_MODEL_739fb4780313415aa57afd5984147598"
            ],
            "layout": "IPY_MODEL_bcb89e9d2d9445d0b8395c4210f671ed"
          }
        },
        "7e943840ec5e4332be182d4ae97e03e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5039614bebce4052a98831d73b3adc86",
            "placeholder": "​",
            "style": "IPY_MODEL_acaa2f959cd7491d8bac252b56cf94fc",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "77a2b00b09da4a969660e7d9a67e0f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a215486f0ad14143989bc8395c89e6f7",
            "max": 454281733,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_136a2e31c29747b5afbbbb507324262c",
            "value": 454281733
          }
        },
        "739fb4780313415aa57afd5984147598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c69857b908d4741b3c92fe78aa86cec",
            "placeholder": "​",
            "style": "IPY_MODEL_deb9a5816f9240e3b76236a0da8913cb",
            "value": " 454M/454M [00:01&lt;00:00, 465MB/s]"
          }
        },
        "bcb89e9d2d9445d0b8395c4210f671ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5039614bebce4052a98831d73b3adc86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acaa2f959cd7491d8bac252b56cf94fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a215486f0ad14143989bc8395c89e6f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "136a2e31c29747b5afbbbb507324262c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c69857b908d4741b3c92fe78aa86cec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb9a5816f9240e3b76236a0da8913cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58c26ac79a0a4085991e21638bc9c2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fdd6250294884a69b38a8af5e27698e7",
              "IPY_MODEL_0acad9a8b3d44c6f81464d2751b538ad",
              "IPY_MODEL_db31767a609b4fe78216b981b18e1706"
            ],
            "layout": "IPY_MODEL_7793fc89b59f4242b3c687d25c7409f4"
          }
        },
        "fdd6250294884a69b38a8af5e27698e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_461ab26ffc3e4c7ab1f6eb4d08e829a8",
            "placeholder": "​",
            "style": "IPY_MODEL_09740d9d8c504985bca48aa0b000cd2a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0acad9a8b3d44c6f81464d2751b538ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eda39eb16b0c426084027c9ca232bd2f",
            "max": 1263,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f331b2e50b049b9b94acf062b6c45dc",
            "value": 1263
          }
        },
        "db31767a609b4fe78216b981b18e1706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33502d635258412ab8732b350c4272c8",
            "placeholder": "​",
            "style": "IPY_MODEL_ce4453e758bb4f3d9370d78d3401a078",
            "value": " 1.26k/1.26k [00:00&lt;00:00, 163kB/s]"
          }
        },
        "7793fc89b59f4242b3c687d25c7409f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "461ab26ffc3e4c7ab1f6eb4d08e829a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09740d9d8c504985bca48aa0b000cd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eda39eb16b0c426084027c9ca232bd2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f331b2e50b049b9b94acf062b6c45dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33502d635258412ab8732b350c4272c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce4453e758bb4f3d9370d78d3401a078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31f271714f974ab581005ac34f7bfc27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a81a6b21cec34d528f2f2610a6c4b1a4",
              "IPY_MODEL_7b065ba669c142b3996f91741509189d",
              "IPY_MODEL_6f1ff1f9efb14f02a728c6b626c20462"
            ],
            "layout": "IPY_MODEL_c503718bb08f46cbb43cd07bb15064ac"
          }
        },
        "a81a6b21cec34d528f2f2610a6c4b1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0944934bede1457e8d27ff278b36a4a9",
            "placeholder": "​",
            "style": "IPY_MODEL_4d65716a713c45768ccbfa6673c36819",
            "value": "vocab.txt: 100%"
          }
        },
        "7b065ba669c142b3996f91741509189d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08867663c7a748feb7590c319b6aab5c",
            "max": 280136,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91e0bf148b694eb39e3093c04d95f2b2",
            "value": 280136
          }
        },
        "6f1ff1f9efb14f02a728c6b626c20462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aca50438b084058953b36d1f86c7482",
            "placeholder": "​",
            "style": "IPY_MODEL_e13ee617fe1a498db1d73223f6c562f7",
            "value": " 280k/280k [00:00&lt;00:00, 666kB/s]"
          }
        },
        "c503718bb08f46cbb43cd07bb15064ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0944934bede1457e8d27ff278b36a4a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d65716a713c45768ccbfa6673c36819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08867663c7a748feb7590c319b6aab5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e0bf148b694eb39e3093c04d95f2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4aca50438b084058953b36d1f86c7482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13ee617fe1a498db1d73223f6c562f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4c1d4fdd4424a2390895983388af1f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc79d6ca6fae4ed8a07a6e464a40b570",
              "IPY_MODEL_f9dd1c30b0884ecc985eca071b931a5f",
              "IPY_MODEL_c066bf8210d645de8e4690435d87b0cc"
            ],
            "layout": "IPY_MODEL_c71216f216574f5cb104fbbf873ed48c"
          }
        },
        "fc79d6ca6fae4ed8a07a6e464a40b570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_260e9e247a074c68b578b817c7d99cbd",
            "placeholder": "​",
            "style": "IPY_MODEL_af2677d51dd244b59733632d49489118",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f9dd1c30b0884ecc985eca071b931a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28f1d235e63d40af8ac2c4e38d7e9071",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbd67d76ac264af582f4276a5ac8d03d",
            "value": 125
          }
        },
        "c066bf8210d645de8e4690435d87b0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e60d66792234e7c84438b7ca85b929b",
            "placeholder": "​",
            "style": "IPY_MODEL_fda857e1c0c14bbe8ce10e760364a456",
            "value": " 125/125 [00:00&lt;00:00, 15.8kB/s]"
          }
        },
        "c71216f216574f5cb104fbbf873ed48c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260e9e247a074c68b578b817c7d99cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2677d51dd244b59733632d49489118": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f1d235e63d40af8ac2c4e38d7e9071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd67d76ac264af582f4276a5ac8d03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e60d66792234e7c84438b7ca85b929b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda857e1c0c14bbe8ce10e760364a456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/BIG_PROJ # 대규모 jsonl 받아오기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjEK8hL4a_Se",
        "outputId": "da4ea11e-f0ea-40d2-985d-79d127d8175d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BIG_PROJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 사전 설치\n",
        "!pip install transformers datasets chromadb langchain langchain-openai sentence-transformers torch tensorflow tqdm langchain_chroma faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xosQ5QAmeyJa",
        "outputId": "bc39b467-b86d-4ec6-fb40-f75c7c3544b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.14.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.36.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.74.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.2)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.100.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.20-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.32-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_chroma-0.2.5-py3-none-any.whl (12 kB)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=a0511ed61291a3f985533bfeafa00fe11fe6ac1740bf3793d566867d1bf7a05a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, faiss-cpu, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, coloredlogs, onnxruntime, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, chromadb, langchain_chroma\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.20 coloredlogs-15.0.1 durationpy-0.10 faiss-cpu-1.12.0 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 langchain-openai-0.3.32 langchain_chroma-0.2.5 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "access_token = #\n",
        "ACCESS_TOKEN = #\n",
        "\n",
        "OPENAI_API_KEY= #"
      ],
      "metadata": {
        "id": "8Z50-lVv2-Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# db생성"
      ],
      "metadata": {
        "id": "AIPlUBZN3G5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 라이브러리 임포트\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import Document\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "SKOjCz0piU5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# 모든 파일에서 plain_text 수집\n",
        "def collect_all_texts(jsonl_paths):\n",
        "    all_texts = []\n",
        "    for path in jsonl_paths:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            lines = f.readlines()\n",
        "            for line in tqdm(lines, desc=f\"📂 텍스트 수집 중: {os.path.basename(path)}\"):\n",
        "                data = json.loads(line)\n",
        "                text = data[\"metadata\"].get(\"plain_text\")\n",
        "                if text:\n",
        "                    all_texts.append(text)\n",
        "    return all_texts\n",
        "\n",
        "# 토큰 길이 분포 확인\n",
        "def show_token_length_distribution(texts, sample_size=100_000):\n",
        "    import random\n",
        "    sampled = random.sample(texts, k=min(sample_size, len(texts)))\n",
        "    print(f\"🧪 토큰 길이 분석 (샘플 {len(sampled):,}건)\")\n",
        "    lengths = [len(tokenizer.encode(t)) for t in tqdm(sampled, desc=\"🔍 토큰 길이 측정\")]\n",
        "    for p in [50, 75, 90, 95, 99, 99.5, 99.9]:\n",
        "        print(f\"{p:5.1f}퍼센트 이내: {np.percentile(lengths, p):.1f} tokens\")\n",
        "    print(f\"🧵 최대 길이: {max(lengths)} tokens\")\n",
        "# 실행\n",
        "jsonl_paths = [\n",
        "    \"장치-독립항-공개공보-청구항구조화정보.jsonl\",\n",
        "    \"장치-종속항-공개공보-청구항구조화정보.jsonl\"\n",
        "]\n",
        "\n",
        "texts = collect_all_texts(jsonl_paths)\n",
        "show_token_length_distribution(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hesMTZsG9Bp2",
        "outputId": "2072198a-7a68-4c0f-d9e6-0a21be2c8ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📂 텍스트 수집 중: 장치-독립항-공개공보-청구항구조화정보.jsonl: 100%|██████████| 1876515/1876515 [00:10<00:00, 172438.51it/s]\n",
            "📂 텍스트 수집 중: 장치-종속항-공개공보-청구항구조화정보.jsonl: 100%|██████████| 4789718/4789718 [00:26<00:00, 177670.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 토큰 길이 분석 (샘플 100,000건)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 토큰 길이 측정: 100%|██████████| 100000/100000 [00:52<00:00, 1916.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 50.0퍼센트 이내: 45.0 tokens\n",
            " 75.0퍼센트 이내: 67.0 tokens\n",
            " 90.0퍼센트 이내: 99.0 tokens\n",
            " 95.0퍼센트 이내: 130.0 tokens\n",
            " 99.0퍼센트 이내: 224.0 tokens\n",
            " 99.5퍼센트 이내: 277.0 tokens\n",
            " 99.9퍼센트 이내: 472.0 tokens\n",
            "🧵 최대 길이: 2307 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, gc\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import faiss\n",
        "\n",
        "# 설정\n",
        "MODEL_NAME = \"KIPI-ai/KorPatElectra\"\n",
        "ACCESS_TOKEN = \"#\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 모델 및 토크나이저 로딩 (최적화)\n",
        "model = BertModel.from_pretrained(MODEL_NAME, token=ACCESS_TOKEN).to(DEVICE).eval().half()\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, token=ACCESS_TOKEN)\n",
        "\n",
        "# JSONL 로드 함수 (tqdm 포함)\n",
        "def load_jsonl(path):\n",
        "    texts, metadatas = [], []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "        for line in tqdm(lines, desc=f\"📂 텍스트 수집 중: {os.path.basename(path)}\", unit=\"줄\"):\n",
        "            data = json.loads(line)\n",
        "            text = data[\"metadata\"].get(\"plain_text\")\n",
        "            if text:\n",
        "                texts.append(text)\n",
        "                meta = data.get(\"metadata\", {})\n",
        "                meta[\"raw_text\"] = data.get(\"text\")\n",
        "                metadatas.append(meta)\n",
        "    return texts, metadatas\n",
        "\n",
        "# 임베딩 함수 (256 토큰 최적 설정)\n",
        "def embed_texts(texts, batch_size=4096, max_length=256):\n",
        "    vectors = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"🔍 임베딩 중\", unit=\"batch\"):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch, return_tensors=\"pt\", padding=\"max_length\", truncation=True,\n",
        "                           max_length=max_length, return_token_type_ids=False)\n",
        "        inputs = {k: v.to(DEVICE, non_blocking=True) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            outputs = model(**inputs)\n",
        "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "            cls_embeddings = torch.nn.functional.normalize(cls_embeddings, p=2, dim=1)\n",
        "            vectors.append(cls_embeddings.cpu().numpy())\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    return np.vstack(vectors)\n",
        "\n",
        "# FAISS 인덱스 생성 및 저장\n",
        "def build_faiss_index(jsonl_paths, index_save_path, batch_size=4096, chunk_size=500_000, max_length=256):\n",
        "    dim = 768\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    metadata_store = []\n",
        "\n",
        "    for path in jsonl_paths:\n",
        "        texts, metas = load_jsonl(path)\n",
        "        print(f\"📦 {len(texts):,}개 로드됨: {path}\")\n",
        "\n",
        "        for i in range(0, len(texts), chunk_size):\n",
        "            chunk_texts = texts[i:i+chunk_size]\n",
        "            chunk_metas = metas[i:i+chunk_size]\n",
        "\n",
        "            print(f\"🔢 임베딩 중: {i}-{i+len(chunk_texts)}\")\n",
        "            chunk_vectors = embed_texts(chunk_texts, batch_size=batch_size, max_length=max_length)\n",
        "            index.add(chunk_vectors)\n",
        "            metadata_store.extend(chunk_metas)\n",
        "\n",
        "            print(f\"✅ {len(chunk_vectors):,}개 벡터 저장됨 (index size: {index.ntotal:,})\")\n",
        "\n",
        "    faiss.write_index(index, index_save_path)\n",
        "    with open(index_save_path + \".meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metadata_store, f, ensure_ascii=False)\n",
        "    print(f\"🎉 FAISS 인덱스 저장 완료: {index_save_path}\")\n",
        "\n",
        "    return index, metadata_store\n",
        "\n",
        "# 검색 함수\n",
        "def search_faiss(index, query, top_k=3):\n",
        "    with torch.inference_mode():\n",
        "        inputs = tokenizer(query, return_tensors=\"pt\", padding=\"max_length\", truncation=True,\n",
        "                           max_length=256, return_token_type_ids=False).to(DEVICE)\n",
        "        output = model(**inputs).last_hidden_state[:, 0, :]\n",
        "        query_vec = torch.nn.functional.normalize(output, p=2, dim=1).cpu().numpy()\n",
        "    scores, indices = index.search(query_vec, top_k)\n",
        "    return scores[0], indices[0]\n",
        "\n",
        "jsonl_paths = [\n",
        "    \"장치-독립항-공개공보-청구항구조화정보.jsonl\",\n",
        "    \"장치-종속항-공개공보-청구항구조화정보.jsonl\"\n",
        "]\n",
        "\n",
        "index_save_path = \"/content/korpat_index.faiss\"\n",
        "\n",
        "# 벡터 생성 및 저장\n",
        "index, metas = build_faiss_index(jsonl_paths, index_save_path)\n",
        "\n",
        "scores, indices = search_faiss(index, \"배터리 셀을 보호하는 절연 구조\")\n",
        "for rank, idx in enumerate(indices):\n",
        "    print(f\"\\n🔹 Top {rank+1}\")\n",
        "    print(\"📄\", metas[idx].get(\"plain_text\"))\n",
        "    print(\"📑\", metas[idx].get(\"raw_text\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bib21aX__pra",
        "outputId": "71b42532-78e4-4f7a-861c-fb6f13b2a1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "📂 텍스트 수집 중: 장치-독립항-공개공보-청구항구조화정보.jsonl: 100%|██████████| 1876515/1876515 [00:10<00:00, 182733.39줄/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 1,876,502개 로드됨: 장치-독립항-공개공보-청구항구조화정보.jsonl\n",
            "🔢 임베딩 중: 0-500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [07:13<00:00,  3.52s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 500,000)\n",
            "🔢 임베딩 중: 500000-1000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [06:42<00:00,  3.27s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 1,000,000)\n",
            "🔢 임베딩 중: 1000000-1500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [06:38<00:00,  3.24s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 1,500,000)\n",
            "🔢 임베딩 중: 1500000-1876502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 92/92 [05:12<00:00,  3.39s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 376,502개 벡터 저장됨 (index size: 1,876,502)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "📂 텍스트 수집 중: 장치-종속항-공개공보-청구항구조화정보.jsonl: 100%|██████████| 4789718/4789718 [00:29<00:00, 163642.33줄/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 4,789,718개 로드됨: 장치-종속항-공개공보-청구항구조화정보.jsonl\n",
            "🔢 임베딩 중: 0-500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:38<00:00,  4.71s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 2,376,502)\n",
            "🔢 임베딩 중: 500000-1000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:30<00:00,  4.64s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 2,876,502)\n",
            "🔢 임베딩 중: 1000000-1500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:23<00:00,  4.58s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 3,376,502)\n",
            "🔢 임베딩 중: 1500000-2000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:20<00:00,  4.55s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 3,876,502)\n",
            "🔢 임베딩 중: 2000000-2500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:25<00:00,  4.60s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 4,376,502)\n",
            "🔢 임베딩 중: 2500000-3000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:30<00:00,  4.64s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 4,876,502)\n",
            "🔢 임베딩 중: 3000000-3500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:28<00:00,  4.62s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 5,376,502)\n",
            "🔢 임베딩 중: 3500000-4000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:32<00:00,  4.65s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 5,876,502)\n",
            "🔢 임베딩 중: 4000000-4500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 123/123 [09:42<00:00,  4.73s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 500,000개 벡터 저장됨 (index size: 6,376,502)\n",
            "🔢 임베딩 중: 4500000-4789718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 임베딩 중: 100%|██████████| 71/71 [05:46<00:00,  4.88s/batch]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 289,718개 벡터 저장됨 (index size: 6,666,220)\n",
            "🎉 FAISS 인덱스 저장 완료: /content/korpat_index.faiss\n",
            "\n",
            "🔹 Top 1\n",
            "📄 상기 배터리 셀을 보호하는 셀 보호 회로와\n",
            "📑 <ANY>상기 배터리 셀</ANY><RELATION_321>을 보호하는</RELATION_321> <COMPONENT>셀 보호 회로</COMPONENT>와\n",
            "\n",
            "🔹 Top 2\n",
            "📄 전극 탭을 포함하는 배터리 셀\n",
            "📑 <ANY>전극 탭</ANY><RELATION_3>을 포함하는</RELATION_3> <COMPONENT>배터리 셀</COMPONENT>\n",
            "\n",
            "🔹 Top 3\n",
            "📄 전극 탭을 포함하는 배터리 셀\n",
            "📑 <ANY>전극 탭</ANY><RELATION_3>을 포함하는</RELATION_3> <COMPONENT>배터리 셀</COMPONENT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test"
      ],
      "metadata": {
        "id": "xhpe_VG83M5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import faiss\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ✅ 설정\n",
        "INDEX_PATH = \"/content/drive/MyDrive/BIG_PROJ/korpat_index.faiss\"\n",
        "META_PATH = INDEX_PATH + \".meta.json\"\n",
        "MODEL_NAME = \"KIPI-ai/KorPatElectra\"\n",
        "ACCESS_TOKEN = \"#\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # ✅ 모델 및 토크나이저 로딩\n",
        "model = BertModel.from_pretrained(MODEL_NAME, token=ACCESS_TOKEN).to(DEVICE).eval().half()\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, token=ACCESS_TOKEN)\n",
        "\n",
        "# # ✅ FAISS 인덱스 및 메타데이터 로딩\n",
        "# index = faiss.read_index(INDEX_PATH)\n",
        "# with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "#     metadata = json.load(f)\n",
        "\n",
        "# print(f\"🔗 인덱스 로딩 완료: {index.ntotal:,} vectors\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsVNRcb1rUvT",
        "outputId": "de7e0d28-8161-4eab-9b26-036816b475e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Load metadata if not already loaded\n",
        "if 'metadata' not in locals() or not metadata:\n",
        "    META_PATH = \"/content/drive/MyDrive/BIG_PROJ/korpat_index.faiss.meta.json\"\n",
        "    try:\n",
        "        with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            metadata = json.load(f)\n",
        "        print(f\"🔗 메타데이터 로딩 완료: {len(metadata):,} entries\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ 오류: 메타데이터 파일 '{META_PATH}'를 찾을 수 없습니다.\")\n",
        "        metadata = []\n",
        "\n",
        "# Print the first 10 metadata entries without formatting\n",
        "if metadata:\n",
        "    print(metadata[:10])\n",
        "else:\n",
        "    print(\"\\n⚠️ 메타데이터가 비어있거나 로드되지 않았습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbUunnxz3fCj",
        "outputId": "daabb0f5-07a9-412b-fc7f-7afa76ba2ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'app_num': '1019400024294', 'claim_num': 1, 'is_independent': True, 'sent_num': 1, 'sent_total': 4, 'is_last': False, 'plain_text': '내부에 히터가 설치된 상,하부틀과', 'raw_text': '<ANY>내부에 히터</ANY><RELATION_117>가 설치된</RELATION_117> <COMPONENT>상,하부틀</COMPONENT>과'}, {'app_num': '1019400024294', 'claim_num': 1, 'is_independent': True, 'sent_num': 2, 'sent_total': 4, 'is_last': False, 'plain_text': '상,하부틀의 위치하는 단열재와, 상,하부틀과 단열재사이에 분할되게 삽입되어 단열재와 상,하부틀사이에 공간부를 형성하는 중간체와, 상기 단열제의 외측에 부착되는 판체로 구성된 적충체와', 'raw_text': '<ANY>상,하부틀의 위치하는 단열재와, 상,하부틀과 단열재사이에 분할되게 삽입되어 단열재와 상,하부틀사이에 공간부를 형성하는 중간체와, 상기 단열제의 외측</ANY><RELATION_396841>에 부착되는 판체로 구성된</RELATION_396841> <COMPONENT>적충체</COMPONENT>와'}, {'app_num': '1019400024294', 'claim_num': 1, 'is_independent': True, 'sent_num': 3, 'sent_total': 4, 'is_last': False, 'plain_text': '상기 적충체를 결착하기 위한 채결 수단과', 'raw_text': '<ANY>상기 적충체</ANY><RELATION_214069>를 결착하기 위한</RELATION_214069> <COMPONENT>채결 수단</COMPONENT>과'}, {'app_num': '1019400024294', 'claim_num': 1, 'is_independent': True, 'sent_num': 4, 'sent_total': 4, 'is_last': True, 'plain_text': '그 체결수단을 수용하는 적충체의 구멍과 채결수단사이에 열변형을 방지하기 위한 틈새가 형성된 것을 특징으로 하는 쉐도우 마스크 금형', 'raw_text': '<ANY>그 체결수단을 수용하는</ANY> <COMPONENT>적충체의 구멍과 채결수단사이에 열변형</COMPONENT><RELATION_396840>을 방지하기 위한 틈새가 형성된</RELATION_396840> 것<RELATION_SEP>을 특징으로 하는</RELATION_SEP> <PATENT_ITEM>쉐도우 마스크 금형</PATENT_ITEM>'}, {'app_num': '1019760000726', 'claim_num': 1, 'is_independent': True, 'sent_num': 1, 'sent_total': 1, 'is_last': True, 'plain_text': '신호를 전송 또는 기록되기 전에 그 신호의 다이너믹 레인지를 압축하고 또 전송후 도는 재생후에 신호의 다이너믹 레인지를 신장하게 되었는 잡음 저감 방식에서 압축기는 압축기의 입력신호 다이너믹 레인지에 직선적으로 관계되어 있는 다이너믹 레인지를 가지는 제1신호성분을 출력으로 발생하는 제1회로부와 제2신호 성분이고, 압축기에 의인정되는 레벨증대가 저입력 신호 레벨에서만 일어나고 그리고 고 입력레벨에서는 이 제2신호성분이 전기한 제1신호성분의 레벨의 약 0.1배 이하의 레벨로되는 것 같은 신형 리미터에 의해 제한되어 있는 제2신호 성분을 출력으로서 발생하는 제2회로부를 구비하고 압축은 압축기의 제1회로부에서의 제1신호성분을 압축기의 제2회로부에서의 제2신호 성분에 의해 증대하는 것에 의해 되고 신장되는 신장기의 입력신호의 다이너믹 레인지에 직선적으로 관계하고 있는 다이너믹 레인지를 가지는 제3신호 성분을 출력으로서 발생하는 제1회로부와 제4신호성분이고, 신장기에서의 인정된 레벨 축소가 신장기에 저입력 신호 레벨시에서만 일어나고, 신장기에의 입력신호의 레벨이 높을 때에만 이 제4신호 성분이 전기한 제3신호 성분의 레벨의 약 0.1배 이하의 레벨로 되게 선형 리미터에 의해 제한되어 있는 제4신호성분을 출력으로 해서 발생하게 되어 있고 또한 전기한 압축기의 제2회로부와 동일 또는 실질상 같은 구성을 가진 제2회로부를 구비하고 신장은 신장기의 제1회로부에서의 제3신호 성분을 신장기의 제2회로부에서의 제4신호성분에 의해 축소하는 데 따라서 되게한 것을 특징으로 한 잡음 저감방식', 'raw_text': '<ANY>신호를 전송 또는 기록되기 전에 그 신호의 다이너믹 레인지를 압축하고 또 전송후 도는 재생후에 신호의 다이너믹 레인지를 신장하게 되었는 잡음 저감 방식에서 압축기는 압축기의 입력신호 다이너믹 레인지에 직선적으로 관계되어 있는 다이너믹 레인지를 가지는 제1신호성분을 출력으로 발생하는 제1회로부와 제2신호 성분이고, 압축기에 의인정되는 레벨증대가 저입력 신호 레벨에서만 일어나고 그리고 고 입력레벨에서는 이 제2신호성분이 전기한 제1신호성분의 레벨의 약 0.1배 이하의 레벨로되는 것 같은 신형 리미터에 의해 제한되어 있는 제2신호 성분을 출력으로서 발생하는 제2회로부를 구비하고 압축은 압축기의 제1회로부에서의 제1신호성분을 압축기의 제2회로부에서의 제2신호 성분에 의해 증대하는 것에 의해 되고 신장되는 신장기의 입력신호의 다이너믹 레인지에 직선적으로 관계하고 있는 다이너믹 레인지를 가지는 제3신호 성분을 출력으로서 발생하는 제1회로부와 제4신호성분이고, 신장기에서의 인정된 레벨 축소가 신장기에 저입력 신호 레벨시에서만 일어나고, 신장기에의 입력신호의 레벨이 높을 때에만 이 제4신호 성분이 전기한 제3신호 성분의 레벨의 약 0.1배 이하의 레벨로 되게 선형 리미터에 의해 제한되어 있는 제4신호성분을 출력으로 해서 발생하게 되어 있고 또한 전기한</ANY> <COMPONENT>압축기의 제2회로부</COMPONENT><RELATION_624176>와 동일 또는 실질상 같은</RELATION_624176> 구성<RELATION_SEP>을 가진</RELATION_SEP> <PATENT_ITEM>제2회로부를 구비하고 신장은 신장기의 제1회로부에서의 제3신호 성분을 신장기의 제2회로부에서의 제4신호성분에 의해 축소하는 데 따라서 되게한 것을 특징으로 한 잡음 저감방식</PATENT_ITEM>'}, {'app_num': '1019760000958', 'claim_num': 1, 'is_independent': True, 'sent_num': 1, 'sent_total': 2, 'is_last': False, 'plain_text': '신호가 송신 혹은 기록 이전에 그 다이나믹 범위의 압축을 받아서 수신 또는 재생의 연후에, 신장을 받도록 되어 있으며 압축기 내에서는 압축기의 입력신호의 다이나믹 범위에 대해서 선형관계가 있는 다이나믹 범위에 대해서 선형관계가 있는 다이나믹 범위를 갖는 압축기 제1회로에 의해 주어지는 제1신호성분을 압축기 제2회로로 부터 얻어지는 제2신호성분에 의해서 레벨 증대하는 것에 의해 압축이 행하여지고, 이 제2신호성분은 인저되는 레벨증대가 저입력신호 레벨에서만 발생하도록 제한되어 있고, 고입력신호 레벨에서는 제2신호성분은 상기 제1신호성분의 레벨의 약 0.1배보다 작은 레벨로 제한되어 있으며, 신장기(-) 내에서는 신장기의 입력신호에 대해서 선형관계가 있는 다이나믹 범위를 갖는 신장기 제1회로에 의해 주어지는 제3신호성분을 신장기 제2회로로부터 얻어지는 제4신호 성분에 의해서 레벨 축소하는 것에 의해 신장(-)이 행하여지고, 이 제4신호 성분은 인정된 레벨 축소가 신장기의 입력신호 레벨이 낮을 때만 발생하도록 제한되어 있으며, 신장기의 입력신호 레벨이 높을 때는 이 제4신호성분은 상기 제3신호성분의 레벨의 약 0.1배보다 작은 레벨로 제한되게끔해서 이루어진 잡음 저감 방식이며, 압축기 및 신장기 내에 사용되는 제2회로가 완전히 동일한 회로 또는 실질상 같은 구성의 회로이며, 압축기 내에 있는 제2회로 입력은 압축기의 출력에 결합되며 각기 신장기내에 있어', 'raw_text': '<ANY>신호가 송신 혹은 기록 이전에 그 다이나믹 범위의 압축을 받아서 수신 또는 재생의 연후에, 신장을 받도록 되어 있으며 압축기 내에서는 압축기의 입력신호의 다이나믹 범위에 대해서 선형관계가 있는 다이나믹 범위에 대해서 선형관계가 있는 다이나믹 범위를 갖는 압축기 제1회로에 의해 주어지는 제1신호성분을 압축기 제2회로로 부터 얻어지는 제2신호성분에 의해서 레벨 증대하는 것에 의해 압축이 행하여지고, 이 제2신호성분은 인저되는 레벨증대가 저입력신호 레벨에서만 발생하도록 제한되어 있고, 고입력신호 레벨에서는 제2신호성분은 상기 제1신호성분의 레벨의 약 0.1배보다 작은 레벨로 제한되어 있으며, 신장기(-) 내에서는 신장기의 입력신호에 대해서 선형관계가 있는 다이나믹 범위를 갖는 신장기 제1회로에 의해 주어지는 제3신호성분을 신장기 제2회로로부터 얻어지는 제4신호 성분에 의해서 레벨 축소하는 것에 의해 신장(-)이 행하여지고, 이 제4신호 성분은 인정된 레벨 축소가 신장기의 입력신호 레벨이 낮을 때만 발생하도록 제한되어 있으며, 신장기의 입력신호 레벨이 높을 때는 이 제4신호성분은 상기 제3신호성분의 레벨의 약 0.1배보다 작은 레벨로 제한되게끔해서 이루어진 잡음 저감 방식이며, 압축기 및 신장기 내에 사용되는 제2회로가 완전히 동일한 회로 또는 실질상 같은 구성의 회로이며, 압축기 내에 있는 제2회로 입력은 압축기의 출력에 결합되며 각기 신장기내</ANY><RELATION_PRE><RELATION_2>에 있어</RELATION_2></RELATION_PRE>'}, {'app_num': '1019760000958', 'claim_num': 1, 'is_independent': True, 'sent_num': 2, 'sent_total': 2, 'is_last': True, 'plain_text': '제2회로의 입력은 신장기의 입력에 결합되게끔 한 것을 특징으로 하는 잡음 저감방식', 'raw_text': '<COMPONENT>제2회로의 입력은 신장기의 입력</COMPONENT><RELATION_624993>에 결합되게끔 한</RELATION_624993> 것<RELATION_SEP>을 특징으로 하는</RELATION_SEP> <PATENT_ITEM>잡음 저감방식</PATENT_ITEM>'}, {'app_num': '1019760001613', 'claim_num': 1, 'is_independent': True, 'sent_num': 1, 'sent_total': 1, 'is_last': True, 'plain_text': '대체로 열과 전기적으로 전도성인 금속으로 구성되고 한끝이 접합표면에서 단말되는 리드단자와 대체로 내화성 금속으로 구성되고 전기한 내화성 금속의 접합표면에서 단말되는 접촉단자를 제공하고, 전기한 단자들의 접합표면들을 최소한 융점 450°을 갖는 은과 구리를 기본으로하는 땜질용 합금과 접촉하도록 위치시키며, 그 땜질용 합금을 그 합금을 용해시키는데 충분한 시간 동안 최소한 그것의 융점으로 가열시켜서 단계 용융된 땜질용 합금을 전기한 단자들의 접합표면들과 접촉시켜 냉각 고화시켜 전기한 접촉단자와 전기한 리드단자를 단일구조로 접합시키므로서 접속단자에 리드단자를 부착시킴을 특징으로 하는 황등의 리드(lead) 전극을 만드는 공정과 그 공정의 생산물', 'raw_text': '<ANY>대체로 열과 전기적으로 전도성인 금속으로 구성되고 한끝이 접합표면에서 단말되는 리드단자와 대체로 내화성 금속으로 구성되고 전기한 내화성 금속의 접합표면에서 단말되는 접촉단자를 제공하고, 전기한 단자들의 접합표면들을 최소한 융점 450°을 갖는 은과 구리를 기본으로하는 땜질용 합금과 접촉하도록 위치시키며, 그 땜질용 합금을 그 합금을 용해시키는데 충분한 시간 동안 최소한 그것의 융점으로 가열시켜서 단계 용융된 땜질용 합금을 전기한 단자들의 접합표면들과 접촉시켜 냉각 고화시켜 전기한</ANY> <COMPONENT>접촉단자</COMPONENT><RELATION_614230>와 전기한</RELATION_614230> 리드단자를 단일구조로 접합시키므로서 접속단자에 리드단자를 부착시킴<RELATION_SEP>을 특징으로 하는</RELATION_SEP> <PATENT_ITEM>황등의 리드(lead) 전극을 만드는 공정과 그 공정의 생산물</PATENT_ITEM>'}, {'app_num': '1019760002821', 'claim_num': 1, 'is_independent': True, 'sent_num': 1, 'sent_total': 2, 'is_last': False, 'plain_text': '표준주파수나 또는 상기 표준주파수 부근의 임의의 비표준주파수를 가지는 동조위치와 관련된 무선주파수반송파에 수상기를 동조시키기 위한 장치에 있어서', 'raw_text': '<ANY>표준주파수나 또는 상기 표준주파수 부근의 임의의 비표준주파수를 가지는 동조위치와 관련된 무선주파수반송파에 수상기를 동조시키기 위한 장치</ANY><RELATION_PRE><RELATION_2>에 있어서</RELATION_2></RELATION_PRE>'}, {'app_num': '1019760002821', 'claim_num': 1, 'is_independent': True, 'sent_num': 2, 'sent_total': 2, 'is_last': True, 'plain_text': '국부발진기신호를 발생시키기 위한 제어발진기장치와, 비교적 안정된 주파수신호원과, 상기 무선주파수반송파가 상기 표준주파수일 때 표준값을 가지는 주파수를 가진 적어도 한 정보유지반송파를 내포한 중간주파수신호를 발생시키도록 상기 국부발진기신호와 상기 무선주파수반송파를 결합시키기 위한 혼합기장치와, 상기 국부발진기신호와 상기 안정된 주파수신호간에 예정된 주파수비례관계를 설정하도록 상기 국부발진기신호 및 상기 안정된 주파수신호 중의 적어도 한개에 반응하여 주파수분할되기 위한 제어가능한 주파수분할기(34 또는 38)와, 상기 예정된 주파수 비례관계에 따라 상기 국부발진기신호의 주파수를 제어하기 위해 상기 주파수 분할기와 상기 제어가능한 발진기 사이에 결합된 발진기 제어회로(36,46)와, 상기 국부발진기신호의 주파수와 상기 안정된 주파수신호의 주파수가 비례하는데 의해 제어가능한 인수를 결정하기 위해 상기 제어가능한 주파수분할기에 결합된 주파수분할기 제어회로(26,28,42,56,66,68,70)를 포함하며, 상기 제어가능한 인수는 상기 무선주파수반송파의 상기 표준주파수와 관련된 정격값과 상기 표준주파수 및 비표준파수간의 예기된 편차에 의해 결정된 예정영역내의 양에 의해 상기 정격치로부터 편의된 값을 가지고, 상기 편차는 인접한 동조위치들 간의 분리보다 작으며, 상기 분할기 제어회로는 상기 표준값과 상기 정보유지 반송파의 주파수간의 어떤 편차를 감소시키기 위해 상기 정격값과 편의 값간의 영역내에서 제어가능한 인수를 결정하는 것을 특징으로 하는 비표준주파수반송파용 텔레비죤 주파수 합성기', 'raw_text': '<ANY>국부발진기신호를 발생시키기 위한 제어발진기장치와, 비교적 안정된 주파수신호원과, 상기 무선주파수반송파가 상기 표준주파수일 때 표준값을 가지는 주파수를 가진 적어도 한 정보유지반송파를 내포한 중간주파수신호를 발생시키도록 상기 국부발진기신호와 상기 무선주파수반송파를 결합시키기 위한 혼합기장치와, 상기 국부발진기신호와 상기 안정된 주파수신호간에 예정된 주파수비례관계를 설정하도록 상기 국부발진기신호 및 상기 안정된 주파수신호 중의 적어도 한개에 반응하여 주파수분할되기 위한 제어가능한 주파수분할기(34 또는 38)와, 상기 예정된 주파수 비례관계에 따라 상기 국부발진기신호의 주파수를 제어하기 위해 상기 주파수 분할기와 상기 제어가능한 발진기 사이에 결합된 발진기 제어회로(36,46)와, 상기 국부발진기신호의 주파수와 상기 안정된 주파수신호의 주파수가 비례하는데 의해 제어가능한 인수를 결정하기 위해 상기 제어가능한 주파수분할기에 결합된 주파수분할기 제어회로(26,28,42,56,66,68,70)를 포함하며, 상기 제어가능한 인수는 상기 무선주파수반송파의 상기 표준주파수와 관련된 정격값과 상기 표준주파수 및 비표준파수간의 예기된 편차에 의해 결정된 예정영역내의 양에 의해 상기 정격치로부터 편의된 값을 가지고, 상기 편차는 인접한 동조위치들 간의 분리보다 작으며, 상기 분할기 제어회로는 상기 표준값과 상기 정보유지 반송파의 주파수간의 어떤 편차를 감소시키기 위해 상기 정격값과 편의 값간의 영역내에서 제어가능한</ANY> <COMPONENT>인수</COMPONENT><RELATION_26>를 결정하는</RELATION_26> 것<RELATION_SEP>을 특징으로 하는</RELATION_SEP> <PATENT_ITEM>비표준주파수반송파용 텔레비죤 주파수 합성기</PATENT_ITEM>'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def search_korpat(query, top_k=5):\n",
        "    with torch.inference_mode():\n",
        "        inputs = tokenizer(query, return_tensors=\"pt\", padding=\"max_length\", truncation=True,\n",
        "                           max_length=256, return_token_type_ids=False).to(DEVICE)\n",
        "        vec = model(**inputs).last_hidden_state[:, 0, :]\n",
        "        vec = torch.nn.functional.normalize(vec, p=2, dim=1).cpu().numpy()\n",
        "\n",
        "    scores, indices = index.search(vec, top_k)\n",
        "\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        meta = metadata[idx]\n",
        "        app_no = meta[\"app_num\"]\n",
        "        claim_no = meta[\"claim_num\"]\n",
        "        is_indep = meta[\"is_independent\"]\n",
        "\n",
        "        # 청구항에 속한 모든 문장 추출 및 정렬\n",
        "        claim_sentences = sorted(\n",
        "            [m for m in metadata if m[\"app_num\"] == app_no and m[\"claim_num\"] == claim_no],\n",
        "            key=lambda x: x[\"sent_num\"]\n",
        "        )\n",
        "        full_claim_text = \"\".join([m[\"plain_text\"] for m in claim_sentences])\n",
        "\n",
        "        print(f\"\\n🔹 Top {i+1} (score: {scores[0][i]:.4f})\")\n",
        "        print(f\"🆔 특허번호: {app_no} | 청구항: {claim_no} ({'독립항' if is_indep else '종속항'})\")\n",
        "        print(\"📄 청구항 전체:\", full_claim_text)\n",
        "        print(\"📑 시작 문장 (raw):\", meta[\"raw_text\"][:200])\n",
        "\n",
        "\n",
        "# 예시!\n",
        "search_korpat(\"상,하부틀의 위치하는 단열재와, 상,하부틀과 단열재사이에 분할되게 삽입되어 단열재와 상,하부틀사이에 공간부를 형성하는 중간체와, 상기 단열제의 외측에 부착되는 판체로 구성된 적충체와\", top_k=5)\n",
        "print(\"\\n\\n\")\n",
        "search_korpat(\"본 발명은 자기 터널 접합(magnetic tunnel junction: MTJ)을 구성하기 위해 두 개의 고정층 사이에 하나의 자유층을 샌드위치처럼 순차적으로 수직하게 위치되는 자유층과 고정층 대비 쓰기 효율성을 향상시키는 스핀 주입 토크 자성메모리에 관한 것이다.\", top_k=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqWqFr1AsHar",
        "outputId": "5526a21f-4216-4288-d613-6f0bd12fa39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Top 1 (score: 0.9995)\n",
            "🆔 특허번호: 1019400024294 | 청구항: 1 (독립항)\n",
            "📄 청구항 전체: 내부에 히터가 설치된 상,하부틀과상,하부틀의 위치하는 단열재와, 상,하부틀과 단열재사이에 분할되게 삽입되어 단열재와 상,하부틀사이에 공간부를 형성하는 중간체와, 상기 단열제의 외측에 부착되는 판체로 구성된 적충체와상기 적충체를 결착하기 위한 채결 수단과그 체결수단을 수용하는 적충체의 구멍과 채결수단사이에 열변형을 방지하기 위한 틈새가 형성된 것을 특징으로 하는 쉐도우 마스크 금형\n",
            "📑 시작 문장 (raw): <ANY>상,하부틀의 위치하는 단열재와, 상,하부틀과 단열재사이에 분할되게 삽입되어 단열재와 상,하부틀사이에 공간부를 형성하는 중간체와, 상기 단열제의 외측</ANY><RELATION_396841>에 부착되는 판체로 구성된</RELATION_396841> <COMPONENT>적충체</COMPONENT>와\n",
            "\n",
            "🔹 Top 2 (score: 0.9942)\n",
            "🆔 특허번호: 1020070072388 | 청구항: 2 (종속항)\n",
            "📄 청구항 전체: 청구항 1에 있어서,상기 상,하부 케이스의 마주하는 면에는 서로 대응되는 형상의 돌기와 홈이 각각 형성되어 상기 상,하부 케이스를 조립할 경우 정해진 위치로 안내되어 정확하게 조립될 수구성된것을특징으로 하는커넥터.\n",
            "📑 시작 문장 (raw): <DIRECTION>청구항 1에 있어서,</DIRECTION><COMPONENT>상기 상</COMPONENT><ANY>,하부 케이스의 마주하는 면에는 서로 대응되는 형상의 돌기와 홈이 각각 형성되어 상기 상,하부 케이스를 조립할 경우 정해진 위치로 안내되어 정확하게 조립될 수</ANY><RELATION_015>구성된것을</RELATION_015><RELAT\n",
            "\n",
            "🔹 Top 3 (score: 0.9937)\n",
            "🆔 특허번호: 1020060064458 | 청구항: 1 (독립항)\n",
            "📄 청구항 전체: 빛을 수광하여 전기신호로 변환하는 수광영역과, 상기 수광영역을 외부와 전기적으로 연결하는 범프가 전면에 형성된 촬상소자상기 수광영역을 노출시키는 관통공과, 상기 범프와 연결되도록 후면에 형성되는 전극패드와, 전면에 실장되는 수동소자와, 외부와의 전기적 접속을 위해 전면에 형성되는 단자부를 포함하여 상기 촬상소자 에 결합하는 기판상기 단자부에 연결되어 외부로 연장하는 유연성 인쇄회로기판; 및전면의 광이 상기 수광영역을 향해 입사하도록 전면을 향해 개구되는 개구부와, 상기 개구부 상에 설치되는 렌즈조립체를 포함하며, 상기 기판의 전면에 결합함으로써 상기 촬상소자와 상기 기판을 보호하는 하우징을 포함하는 카메라 모듈\n",
            "📑 시작 문장 (raw): <ANY>상기 수광영역을 노출시키는 관통공과, 상기 범프와 연결되도록 후면에 형성되는 전극패드와, 전면에 실장되는 수동소자와, 외부와의 전기적 접속을 위해 전면에 형성되는 단자부를 포함하여 상기 촬상소자</ANY> <RELATION_623158>에 결합하는</RELATION_623158> <COMPONENT>기판</COMPONENT>\n",
            "\n",
            "🔹 Top 4 (score: 0.9937)\n",
            "🆔 특허번호: 1019997010661 | 청구항: 1 (독립항)\n",
            "📄 청구항 전체: 데이터 트랜스시버를 형성하는 단말기(10)와 상기 단말기의 활동 범위내에 있는 하나 또는 그 이상의 휴대용 물체들(14) 간의 유도 결합에 의해 비금속 쌍방향 통신이 이루어지는, 접촉없이 데이터를 교환하기 위한 시스템으로서,상기 시스템은, 단말기와 함께, 상기 활동 범위 내에 위치되는 휴대용 물체와의 통신을 모방하기 위하여 유도 결합에 의해 상기 단말기와 함께 동작하기에 적절한 회로를 포함하는 테스트 모듈(20)로 구성되며상기 단말기는 상기 테스트 모듈과의 통신을 확인하고, 상기 테스트 모듈과의 완전한 통신 또는 불완전한 통신을 결정하며, 통신이 불완전한 경우 폴트 신호를 발생시키기에 적절한 기능 테스트 수단을 구비하는 것을 특징으로 하는 시스템\n",
            "📑 시작 문장 (raw): <ANY>상기 시스템은, 단말기와 함께, 상기 활동 범위 내에 위치되는 휴대용 물체와의 통신을 모방하기 위하여 유도 결합에 의해 상기 단말기와 함께 동작하기에 적절한</ANY> <COMPONENT>회로</COMPONENT><RELATION_436065>를 포함하는 테스트 모듈(20)로 구성되며</RELATION_436065>\n",
            "\n",
            "🔹 Top 5 (score: 0.9936)\n",
            "🆔 특허번호: 1019990046929 | 청구항: 5 (종속항)\n",
            "📄 청구항 전체: 제 3 항에 있어서,인출단자는 가스켓의 상부 플레이트와 상향 플랜지로 구성된 안착부의 안쪽으로 설치되는 비원형 헤드부와, 그 헤드부에서 연장되어 중공을 관통하는 로드부와, 절연체의 하부에 형성되는리벳팅부를포함하는밀폐전지.\n",
            "📑 시작 문장 (raw): <DIRECTION>제 3 항에 있어서,</DIRECTION><COMPONENT>인출단자</COMPONENT><ANY>는 가스켓의 상부 플레이트와 상향 플랜지로 구성된 안착부의 안쪽으로 설치되는 비원형 헤드부와, 그 헤드부에서 연장되어 중공을 관통하는 로드부와, 절연체의 하부에 형성되는</ANY><COMPONENT>리벳</COMPONENT><RELATION\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "🔹 Top 1 (score: 0.9953)\n",
            "🆔 특허번호: 1020097004675 | 청구항: 43 (종속항)\n",
            "📄 청구항 전체: 제 42 항에 있어서,상기 명령들은, 상기 프로세서로 하여금,상기 하나 이상의 파라미터 값들 중 하나 이상으로 수평의 선명화 필터 (fh) 파라미터 값을 설정함으로써 후광 효과를 감소시키도록 상기 수평의 선명화 필터의 상기 제 1 저역 통과 성분을 구성하게 하고;상기 하나 이상의 파라미터 값들 중 하나 이상으로 수평의 선명화 필터 (fh) 파라미터 값을 설정함으로써 상기 후광 효과를 감소시키도록 상기 수평의 선명화 필터의 상기 제 1 고역 통과 성분구성하게 하는,컴퓨터 판독가능 매체.\n",
            "📑 시작 문장 (raw): <DIRECTION>제 42 항에 있어서,</DIRECTION><COMPONENT>상기 명령들</COMPONENT><ANY>은, 상기 프로세서로 하여금,상기 하나 이상의 파라미터 값들 중 하나 이상으로 수평의 선명화 필터 (fh) 파라미터 값을 설정함으로써 후광 효과를 감소시키도록 상기 수평의 선명화 필터의 상기 제 1 저역 통과 성분을 구성하게 하고;상기\n",
            "\n",
            "🔹 Top 2 (score: 0.9952)\n",
            "🆔 특허번호: 1020070020626 | 청구항: 1 (독립항)\n",
            "📄 청구항 전체: 송신광을 출사하는 반도체 레이저상기 반도체 레이저로부터 출사한 상기 송신광이 광학적으로 결합하여 전파되는 광섬유상기 광섬유와 상기 반도체 레이저의 사이의 광로 상에 배치되어 상기 광섬유의 단면에 융착(融着)한 원주상(狀) 렌즈로서, 상기 반도체 레이저측에서의, 상기 반도체 레이저의 개구수의 1.4배 이상인 개구수를 갖고, 입사한 상기 송신광을 평행광화하는 제1 grin( gr aded in dex)렌즈부와, 상기 광섬유측에서의, 상기 광섬유와 동일한 개구수를 갖고, 상기 제1 grin 렌즈부를 투과한 송신광을 상기 광섬유에 광학적으로 결합시키는 제2 grin 렌즈부를 갖는 결합 렌즈; 및상기 반도체 레이저로부터 출사한 상기 송신광이 상기 결합 렌즈 경유에 의해 상기 광섬유에 광학적으로 결합가능하도록, 적어도 상기 결합 렌즈 또는 상기 광섬유의 일부를 고정하여 지지하는 렌즈대를 구비하는 반도체 레이저 모듈\n",
            "📑 시작 문장 (raw): <ANY>상기 광섬유와 상기 반도체 레이저의 사이의 광로 상에 배치되어 상기 광섬유의 단면에 융착(融着)한 원주상(狀) 렌즈로서, 상기 반도체 레이저측에서의, 상기 반도체 레이저의 개구수의 1.4배 이상인 개구수를 갖고, 입사한 상기 송신광을 평행광화하는 제1 grin( gr aded in dex)렌즈부와, 상기 광섬유측에서의, 상기 광섬유와 동일한 개구수\n",
            "\n",
            "🔹 Top 3 (score: 0.9952)\n",
            "🆔 특허번호: 1020060129155 | 청구항: 9 (종속항)\n",
            "📄 청구항 전체: 제6항에 있어서,상기 도너 안테나와 상기 서비스 안테나 중 적어도 하나가 장착된 수평패널과;상기 모터가 장착된 고정단을 포함하고,상기 안테나이동메카니즘은 상기 모터의 회전 운동을 상기 수평패널의 직선 운동으로 변환시키기 위해 상기 모터에 장착되는 수직베벨기어와, 상기 수직베벨기어에 치합되어 회전하는 수평베벨기어와, 상기 수평베벨기어의 축의 타단에 장착되는 피니언과, 상기 상부 프레임의 일측에 장착되어 상기 피니언에 치합되는랙기어포함하는것을특징으로 하는무선통신 중계기.\n",
            "📑 시작 문장 (raw): <DIRECTION>제6항에 있어서,</DIRECTION><COMPONENT>상기 도너 안테나와 상기 서비스 안테나 중 적어도 하나</COMPONENT><ANY>가 장착된 수평패널과;상기 모터가 장착된 고정단을 포함하고,상기 안테나이동메카니즘은 상기 모터의 회전 운동을 상기 수평패널의 직선 운동으로 변환시키기 위해 상기 모터에 장착되는 수직베벨기어와, 상기\n",
            "\n",
            "🔹 Top 4 (score: 0.9952)\n",
            "🆔 특허번호: 1020080135229 | 청구항: 5 (종속항)\n",
            "📄 청구항 전체: 제4항에 있어서,상기 베이어 노이즈 제거부는,상기 베이어 이미지 데이터에서 소정 수평 라인의 화소값들과 상기 소정 수평 라인과 동일한 화소 성분을 가지는 인접 수평 라인의 화소값들 중 동일한 열에 속하는 화소값들의 차이값을 구하여 미리 설정된 가중치를 곱한 후, 상기 가중치가 곱해진 값들의 평균을 구하여 수평 라인에 대한 에지 성분값을 구한 후, 적어도 하나의 상기 수평 라인에 대한 에지 성분값 각각에 대한 절대값들의 평균을 구함으로써상기수형방향의에지성분구하는것을특징으로 하는이미지 처리 장치.\n",
            "📑 시작 문장 (raw): <DIRECTION>제4항에 있어서,</DIRECTION><COMPONENT>상기 베이어 노이즈 제거부</COMPONENT><ANY>는,상기 베이어 이미지 데이터에서 소정 수평 라인의 화소값들과 상기 소정 수평 라인과 동일한 화소 성분을 가지는 인접 수평 라인의 화소값들 중 동일한 열에 속하는 화소값들의 차이값을 구하여 미리 설정된 가중치를 곱한 후, 상기\n",
            "\n",
            "🔹 Top 5 (score: 0.9951)\n",
            "🆔 특허번호: 1020010070572 | 청구항: 3 (종속항)\n",
            "📄 청구항 전체: 제1항 또는 제2항에 있어서,상기 수평이동수단은,그 일측에 상기 바이트가 장착된 수평슬라이드부와, 상기 수평슬라이드부의 타측에 연결되어 그 수평슬라이드부를 수평방향으로 이동시키기 위한 레일을 구비한 수평케이스부와, 상기 수평슬라이드부를 상기 수평케이스의 레일에 따라 이동시키기 위한구동부로이루어진것을특징으로 하는컨디셔닝 장치.\n",
            "📑 시작 문장 (raw): <DIRECTION>제1항 또는 제2항에 있어서,</DIRECTION><COMPONENT>상기 수평이동수단</COMPONENT><ANY>은,그 일측에 상기 바이트가 장착된 수평슬라이드부와, 상기 수평슬라이드부의 타측에 연결되어 그 수평슬라이드부를 수평방향으로 이동시키기 위한 레일을 구비한 수평케이스부와, 상기 수평슬라이드부를 상기 수평케이스의 레일에 따라 \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "🔹 Top 1 (score: 0.9958)\n",
            "🆔 특허번호: 1020030101424 | 청구항: 2 (종속항)\n",
            "📄 청구항 전체: 제 1 항에 있어서,상기 슬라이딩 장치의 양 종단부에 결합되어 상면커버가 이탈되거나 흔들리는 것을 방지하기 위해, 함체 전면도어 및/또는 후면도어의 내측면 상부에슬라이드고정용브라켓각각형성된것을특징으로 하는옥외형 통신시스템 함체의 차양장치.\n",
            "📑 시작 문장 (raw): <DIRECTION>제 1 항에 있어서,</DIRECTION><COMPONENT>상기 슬라이딩 장치</COMPONENT><ANY>의 양 종단부에 결합되어 상면커버가 이탈되거나 흔들리는 것을 방지하기 위해, 함체 전면도어 및/또는 후면도어의 내측면 상부에</ANY><COMPONENT>슬라이드고정용브라켓</COMPONENT><RELATION_009>각각형성된것\n",
            "\n",
            "🔹 Top 2 (score: 0.9956)\n",
            "🆔 특허번호: 1020130143697 | 청구항: 15 (종속항)\n",
            "📄 청구항 전체: 제13항에 있어서,상기 제1스케줄링의 정보는 상기 다수의 tp들 각각이 변조 및 코딩 방식(modulation and coding scheme: mcs)을 결정하기 위한 링크 적응(link adaptation) 동작을 수행하기 위해사용됨을특징으로 하는중앙 스케줄러.\n",
            "📑 시작 문장 (raw): <DIRECTION>제13항에 있어서,</DIRECTION><COMPONENT>상기 제1스케줄링의 정보</COMPONENT><ANY>는 상기 다수의 tp들 각각이 변조 및 코딩 방식(modulation and coding scheme: mcs)을 결정하기 위한 링크 적응(link adaptation) 동작을 수행하기 위해</ANY><RELATION_026>\n",
            "\n",
            "🔹 Top 3 (score: 0.9955)\n",
            "🆔 특허번호: 1020100008666 | 청구항: 8 (종속항)\n",
            "📄 청구항 전체: 제 7 항에 있어서,상기 제1은닉부는, 상기 나머지 영역 매크로블록들을 하기의 수학식 3을 이용하여 산출한 상기 모션 벡터 평균을 이용하여 보간하는 것을 특징으로 하는 h.264/avc 복호기의 영역별 에러 은닉 장치.  [수학식 3] 여기서 n은 영상의수평축에 속하는매크로블록수를 의미함.\n",
            "📑 시작 문장 (raw): <DIRECTION>제 7 항에 있어서,</DIRECTION><COMPONENT>상기 제1은닉부</COMPONENT><ANY>는, 상기 나머지 영역 매크로블록들을 하기의 수학식 3을 이용하여 산출한 상기 모션 벡터 평균을 이용하여 보간하는 것을 특징으로 하는 h.264/avc 복호기의 영역별 에러 은닉 장치.  [수학식 3] 여기서 n은 영상의</ANY><\n",
            "\n",
            "🔹 Top 4 (score: 0.9955)\n",
            "🆔 특허번호: 1020090130867 | 청구항: 9 (종속항)\n",
            "📄 청구항 전체: 제 1항에 있어서,상기 공격 방지 장비는 감염 단말의 발생 또는 장비 결함과 같은 이상 상황 발생시 별도의 지정된 통신 포트(port)를 이용하여 상기 관제센터 서버로 해당 상황을 전송하는 것을더포함하는것을특징으로 하는분산 서비스 거부 공격 생성 방지 장치.\n",
            "📑 시작 문장 (raw): <DIRECTION>제 1항에 있어서,</DIRECTION><COMPONENT>상기 공격 방지 장비</COMPONENT><ANY>는 감염 단말의 발생 또는 장비 결함과 같은 이상 상황 발생시 별도의 지정된 통신 포트(port)를 이용하여 상기 관제센터 서버로 해당 상황을 전송하는 것을</ANY><RELATION_003>더포함하는것을</RELATION_003\n",
            "\n",
            "🔹 Top 5 (score: 0.9955)\n",
            "🆔 특허번호: 1020047014820 | 청구항: 37 (종속항)\n",
            "📄 청구항 전체: 제 36 항에 있어서,상기 이동국은 상기 순방향 링크 펀디케이티드 채널 상에 수신되는 데이터 프레임의 프레임 에러율(fer)을 검출함으로써 에러율 기반으로 한 순방향 링크 감독을 수행하는 것을 특징으로 하는 무선 통신 네트워크사용하기 위한이동국.\n",
            "📑 시작 문장 (raw): <DIRECTION>제 36 항에 있어서,</DIRECTION><COMPONENT>상기 이동국</COMPONENT><ANY>은 상기 순방향 링크 펀디케이티드 채널 상에 수신되는 데이터 프레임의 프레임 에러율(fer)을 검출함으로써 에러율 기반으로 한 순방향 링크 감독을 수행하는 것을 특징으로 하는 무선 통신 네트워크</ANY><RELATION_SEP>사용하\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1/4조각"
      ],
      "metadata": {
        "id": "bmq0HHUC3VdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import faiss\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 설정\n",
        "INDEX_PATH = \"/content/drive/MyDrive/BIG_PROJ/korpat_index.faiss\"\n",
        "META_PATH = INDEX_PATH + \".meta.json\"\n",
        "OUT_INDEX_PATH = \"/content/korpat_index_quarter_IP.faiss\"\n",
        "OUT_META_PATH = OUT_INDEX_PATH + \".meta.json\"\n",
        "TARGET_RATIO = 0.25  # 1/4\n",
        "\n",
        "# 인덱스와 메타데이터 로드\n",
        "print(\"📦 Loading index...\")\n",
        "index = faiss.read_index(INDEX_PATH)\n",
        "\n",
        "print(\"📄 Loading metadata...\")\n",
        "with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "assert index.ntotal == len(metadata), \"❗ 인덱스와 메타데이터 수 불일치\"\n",
        "\n",
        "# 그룹핑 (app_num + claim_num)\n",
        "group_to_indices = defaultdict(list)\n",
        "for idx, meta in enumerate(metadata):\n",
        "    key = f\"{meta['app_num']}_{meta['claim_num']}\"\n",
        "    group_to_indices[key].append(idx)\n",
        "\n",
        "# 무작위 섞기\n",
        "group_keys = list(group_to_indices.keys())\n",
        "random.shuffle(group_keys)\n",
        "\n",
        "# 목표 수만큼 그룹 선택\n",
        "selected_indices = []\n",
        "current_total = 0\n",
        "target_total = int(len(metadata) * TARGET_RATIO)\n",
        "\n",
        "for key in tqdm(group_keys):\n",
        "    indices = group_to_indices[key]\n",
        "    if current_total + len(indices) > target_total:\n",
        "        continue\n",
        "    selected_indices.extend(indices)\n",
        "    current_total += len(indices)\n",
        "    if current_total >= target_total:\n",
        "        break\n",
        "\n",
        "print(f\"✅ 선택된 벡터 수: {current_total:,} / {len(metadata):,}\")\n",
        "\n",
        "# 선택된 벡터 추출\n",
        "print(\"🎯 선택된 벡터 추출 중...\")\n",
        "dim = index.d\n",
        "new_index = faiss.IndexFlatIP(dim)\n",
        "\n",
        "# reconstruct 후 정규화\n",
        "selected_vectors = np.stack([index.reconstruct(i) for i in selected_indices])\n",
        "selected_vectors = F.normalize(torch.tensor(selected_vectors), p=2, dim=1).numpy()\n",
        "new_index.add(selected_vectors.astype(\"float32\"))\n",
        "\n",
        "# 새 메타데이터 추출\n",
        "selected_metadata = [metadata[i] for i in selected_indices]\n",
        "\n",
        "# 저장\n",
        "print(\"💾 Saving...\")\n",
        "faiss.write_index(new_index, OUT_INDEX_PATH)\n",
        "with open(OUT_META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(selected_metadata, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"🎉 Done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJDMZt_CbDQK",
        "outputId": "823612ff-ca21-47e6-f943-e22eb70bc516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Loading index...\n",
            "📄 Loading metadata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 1299747/5205677 [00:02<00:06, 624102.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 선택된 벡터 수: 1,666,555 / 6,666,220\n",
            "🎯 선택된 벡터 추출 중...\n",
            "💾 Saving...\n",
            "🎉 Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 메타데이터 확인"
      ],
      "metadata": {
        "id": "uDZx2Zfc20rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first 10 selected metadata entries with is_independent: True in a readable format\n",
        "if selected_metadata:\n",
        "    independent_metadata = [meta for meta in selected_metadata if meta.get('is_independent') is True]\n",
        "    print(f\"\\n📋 선택된 독립항 메타데이터 미리보기 (상위 {min(10, len(independent_metadata))}개):\")\n",
        "    for i, meta in enumerate(independent_metadata[:10]):\n",
        "        print(f\"\\n--- Entry {i+1} ---\")\n",
        "        for key, value in meta.items():\n",
        "            # Limit output length for readability\n",
        "            if isinstance(value, str) and len(value) > 200:\n",
        "                print(f\"{key}: {value[:200]}...\")\n",
        "            else:\n",
        "                print(f\"{key}: {value}\")\n",
        "else:\n",
        "    print(\"\\n⚠️ 선택된 메타데이터가 비어있습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbqgCZU0-luE",
        "outputId": "54e29e1a-3d68-4bf6-c7e6-c3d230a29af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📋 선택된 독립항 메타데이터 미리보기 (상위 10개):\n",
            "\n",
            "--- Entry 1 ---\n",
            "app_num: 2019950018228\n",
            "claim_num: 1\n",
            "is_independent: True\n",
            "sent_num: 1\n",
            "sent_total: 1\n",
            "is_last: True\n",
            "plain_text: 1. 메인샤시(12)의 일측면 상부로 부터는 상·하면의 중심에 스크류체결홈(14)이 형성된 체결보스(16)가 일정한 높이로 절곡 형성되고, 상기 체결보스(16)의 형성위치에 해당되는 메인베이스(18)의 면상에는 스크류관통공(20)이, 상기 체결보스(16)의 형성위치에 해당되는 하부커버(22)의 면상에는 중심에 스크류관통공(20)이 형성된 절곡부(24)가 윗...\n",
            "raw_text: <ANY>1. 메인샤시(12)의 일측면 상부로 부터는 상·하면의 중심에 스크류체결홈(14)이 형성된 체결보스(16)가 일정한 높이로 절곡 형성되고, 상기 체결보스(16)의 형성위치에 해당되는 메인베이스(18)의 면상에는 스크류관통공(20)이, 상기 체결보스(16)의 형성위치에 해당되는 하부커버(22)의 면상에는 중심에 스크류관통공(20)이 형성된 절곡부(2...\n",
            "\n",
            "--- Entry 2 ---\n",
            "app_num: 1020150066943\n",
            "claim_num: 1\n",
            "is_independent: True\n",
            "sent_num: 1\n",
            "sent_total: 4\n",
            "is_last: False\n",
            "plain_text: 복수개의 프레임이 개구를 형성하는 프레임부\n",
            "raw_text: <ANY>복수개의 프레임이 개구</ANY><RELATION_20>를 형성하는</RELATION_20> <COMPONENT>프레임부</COMPONENT>\n",
            "\n",
            "--- Entry 3 ---\n",
            "app_num: 1020150066943\n",
            "claim_num: 1\n",
            "is_independent: True\n",
            "sent_num: 2\n",
            "sent_total: 4\n",
            "is_last: False\n",
            "plain_text: 제1 방향으로 인장되어 상기 프레임부에 고정되는 증착용 마스크; 및\n",
            "raw_text: <ANY>제1 방향으로 인장되어 상기 프레임부</ANY><RELATION_73>에 고정되는</RELATION_73> <COMPONENT>증착용 마스크</COMPONENT>; 및\n",
            "\n",
            "--- Entry 4 ---\n",
            "app_num: 1020150066943\n",
            "claim_num: 1\n",
            "is_independent: True\n",
            "sent_num: 3\n",
            "sent_total: 4\n",
            "is_last: False\n",
            "plain_text: 상기 복수개의 프레임 중 어느 하나의 프레임과 이웃하는 다른 프레임 사이에 설치되어, 상기 복수개의 프레임 중 어느 하나의 프레임과 이웃하는 다른 프레임 사이의 거리를 조절하는 간극 조절부\n",
            "raw_text: <ANY>상기 복수개의 프레임 중 어느 하나의 프레임과 이웃하는 다른 프레임 사이에 설치되어, 상기 복수개의 프레임 중 어느 하나의 프레임과 이웃하는 다른 프레임 사이의 거리</ANY><RELATION_70>를 조절하는</RELATION_70> <COMPONENT>간극 조절부</COMPONENT>\n",
            "\n",
            "--- Entry 5 ---\n",
            "app_num: 1020150066943\n",
            "claim_num: 1\n",
            "is_independent: True\n",
            "sent_num: 4\n",
            "sent_total: 4\n",
            "is_last: True\n",
            "plain_text: 를 포함하는, 마스크 프레임 조립체\n",
            "raw_text: <RELATION_SEP>를 포함하는</RELATION_SEP>, <PATENT_ITEM>마스크 프레임 조립체</PATENT_ITEM>\n",
            "\n",
            "--- Entry 6 ---\n",
            "app_num: 1020120094429\n",
            "claim_num: 6\n",
            "is_independent: True\n",
            "sent_num: 1\n",
            "sent_total: 6\n",
            "is_last: False\n",
            "plain_text: 트래픽 요청 신호를 생성하는 신호 생성부\n",
            "raw_text: <ANY>트래픽 요청 신호</ANY><RELATION_9>를 생성하는</RELATION_9> <COMPONENT>신호 생성부</COMPONENT>\n",
            "\n",
            "--- Entry 7 ---\n",
            "app_num: 1020120094429\n",
            "claim_num: 6\n",
            "is_independent: True\n",
            "sent_num: 2\n",
            "sent_total: 6\n",
            "is_last: False\n",
            "plain_text: 데이터 관련 정보를 포함한 정책 요청 신호를 정책 제공 장치로 전송하고, 상기 정책 요청 신호에 대응하는 정책 응답 신호를 수신하는 정책 관리부\n",
            "raw_text: <ANY>데이터 관련 정보를 포함한 정책 요청 신호를 정책 제공 장치로 전송하고, 상기 정책 요청 신호에 대응하는 정책 응답 신호</ANY><RELATION_11>를 수신하는</RELATION_11> <COMPONENT>정책 관리부</COMPONENT>\n",
            "\n",
            "--- Entry 8 ---\n",
            "app_num: 1020120094429\n",
            "claim_num: 6\n",
            "is_independent: True\n",
            "sent_num: 3\n",
            "sent_total: 6\n",
            "is_last: False\n",
            "plain_text: 경로 네트워크를 경유하여 컨텐츠 제공 장치로부터 상기 트래픽 요청 신호에 대응하는 트래픽 응답 신호를 다운로드하는 트래픽 송수신부\n",
            "raw_text: <ANY>경로 네트워크를 경유하여 컨텐츠 제공 장치로부터 상기 트래픽 요청 신호에 대응하는 트래픽 응답 신호</ANY><RELATION_1327>를 다운로드하는</RELATION_1327> <COMPONENT>트래픽 송수신부</COMPONENT>\n",
            "\n",
            "--- Entry 9 ---\n",
            "app_num: 1020120094429\n",
            "claim_num: 6\n",
            "is_independent: True\n",
            "sent_num: 4\n",
            "sent_total: 6\n",
            "is_last: False\n",
            "plain_text: 상기 정책 응답 신호를 근거로 상기 경로 네트워크의 네트워크 상태를 인지하는 단말 네트워크 인지부; 및\n",
            "raw_text: <ANY>상기 정책 응답 신호를 근거로 상기 경로 네트워크의 네트워크 상태</ANY><RELATION_1380>를 인지하는</RELATION_1380> <COMPONENT>단말 네트워크 인지부</COMPONENT>; 및\n",
            "\n",
            "--- Entry 10 ---\n",
            "app_num: 1020120094429\n",
            "claim_num: 6\n",
            "is_independent: True\n",
            "sent_num: 5\n",
            "sent_total: 6\n",
            "is_last: False\n",
            "plain_text: 상기 다운로드 시 상기 네트워크 상태에 근거하여 트래픽 제어 여부를 판단하고, 판단된 상기 트래픽 제어 여부에 근거하여 상기 다운로드를 제어하는 트래픽 제어부\n",
            "raw_text: <ANY>상기 다운로드 시 상기 네트워크 상태에 근거하여 트래픽 제어 여부를 판단하고, 판단된 상기 트래픽 제어 여부에 근거하여 상기 다운로드</ANY><RELATION_16>를 제어하는</RELATION_16> <COMPONENT>트래픽 제어부</COMPONENT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "HVXYCL9Y4HBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def search_korpat(query, top_k=5, index=new_index, metadata=selected_metadata):\n",
        "    with torch.inference_mode():\n",
        "        inputs = tokenizer(query, return_tensors=\"pt\", padding=\"max_length\", truncation=True,\n",
        "                           max_length=256, return_token_type_ids=False).to(DEVICE)\n",
        "        vec = model(**inputs).last_hidden_state[:, 0, :]\n",
        "        vec = torch.nn.functional.normalize(vec, p=2, dim=1).cpu().numpy()\n",
        "\n",
        "    scores, indices = index.search(vec, top_k)\n",
        "\n",
        "    for i, idx in enumerate(indices[0]):\n",
        "        meta = metadata[idx]\n",
        "        app_no = meta[\"app_num\"]\n",
        "        claim_no = meta[\"claim_num\"]\n",
        "        is_indep = meta[\"is_independent\"]\n",
        "\n",
        "        # 청구항에 속한 모든 문장 추출 및 정렬\n",
        "        claim_sentences = sorted(\n",
        "            [m for m in metadata if m[\"app_num\"] == app_no and m[\"claim_num\"] == claim_no],\n",
        "            key=lambda x: x[\"sent_num\"]\n",
        "        )\n",
        "        full_claim_text = \"\".join([m[\"plain_text\"] for m in claim_sentences])\n",
        "\n",
        "        print(f\"\\n🔹 Top {i+1} (score: {scores[0][i]:.4f})\")\n",
        "        print(f\"🆔 특허번호: {app_no} | 청구항: {claim_no} ({'독립항' if is_indep else '종속항'})\")\n",
        "        print(\"📄 청구항 전체:\", full_claim_text)\n",
        "        print(\"📑 시작 문장 (raw):\", meta['raw_text'][:200])\n",
        "\n",
        "# 예시!\n",
        "search_korpat(\"상,하부틀의 위치하는 단열재와, 상,하부틀과 단열재사이에 분할되게 삽입되어 단열재와 상,하부틀사이에 공간부를 형성하는 중간체와, 상기 단열제의 외측에 부착되는 판체로 구성된 적충체와\", top_k=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZD1pgNoCnAA",
        "outputId": "9f97d13b-b1f5-47ec-e4cd-4e34341f88e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Top 1 (score: 0.9938)\n",
            "🆔 특허번호: 1019980060607 | 청구항: 1 (독립항)\n",
            "📄 청구항 전체: 상부 내측면에 스테이터 코어가 마련되며, 중심면에는 관통구멍이 형성된 하우징과상기 하우징의 관통구멍에 하단부가 억지 끼워 삽입되는 고정축과하부 내측면에 요크와 마그네트가 마련되며, 중심면에는 가이드 구멍이 관통 형성되고, 이 가이드 구멍의 내주면과 고정축 사이에 소정간격으로 개재되는 상,하부 볼 베어링을 통해 고정축에 회전 가능하게 구름 베어링 지지되는 허브와상기 허브와 고정축 사이에 마련되어 상기 상,하부 볼 베어링을 지지하는 베어링 지지수단을 포함하여 된 것을 특징으로 하는 자기 디스크 구동모터\n",
            "📑 시작 문장 (raw): <COMPONENT>하부 내측면에 요크와 마그네트가 마련되며, 중심면에는 가이드 구멍이 관통 형성되고, 이 가이드 구멍의 내주면과 고정축 사이에 소정간격으로 개재되는 상,하부 볼 베어링을 통해 고정축에 회전 가능하게 구름 베어링 지지되는 허브</COMPONENT>와\n",
            "\n",
            "🔹 Top 2 (score: 0.9936)\n",
            "🆔 특허번호: 1019870000924 | 청구항: 21 (독립항)\n",
            "📄 청구항 전체: 전기응용기기를 제어하는 프로그램타이머에 있어서,하우징수단과, 하우징 수단상에 설치된 감속기 수단과,하우징수단에 설치되고 감속기 수단을 구동시키도록 접속된 타이밍모터와, 하우징수단상에서 회전 전진 하도록 설치된 주기간캠과,주기간캠의 적절한 시기의 전진을 하게하고, 래치휘일과 접촉하는 전진포올을 구비하면서, 전진포올이 래치휘일을 전진시키는 진동을 하도록 감속기 수단에 작동가능하게 접속되게한 전진수단과,하우징수단상에 저어널되는 표면과,그의 내측주변부 상에 형성된 톱니를 가진 링기어를 구비하며, 톱니가 저어널되는 표면상에 직접 저어널된 포인트로 되게한 프로그램타이머와, 링기어톱니와 결합하고 링기어를 구동시키는 감속기에 작동가능하게 접속된 피니언수단과,스위치수단과,부기간 캠수단에 응동하고 부기간캠수단의 전진에 응동하여 스위치수단을 작동시키고 정지시키도록 작동가능한 캠플로워 수단들로 이루어진 프로그램타이머\n",
            "📑 시작 문장 (raw): <ANY>그의 내측주변부 상에 형성된 톱니를 가진 링기어를 구비하며, 톱니가 저어널되는 표면상에 직접 저어널된 포인트로 되게한 프로그램타이머와, 링기어톱니와 결합하고 링기어</ANY><RELATION_398830>를 구동시키는 감속기에 작동가능하게 접속된</RELATION_398830> <COMPONENT>피니언수단</COMPONENT>과,\n",
            "\n",
            "🔹 Top 3 (score: 0.9935)\n",
            "🆔 특허번호: 2020070011205 | 청구항: 1 (독립항)\n",
            "📄 청구항 전체: 상측바, 하측바 및 좌우측바가 사각틀체를 형성하도록 결합되며 상기 좌우측바 사이에는 다수개의 지지바가 일정간격 이격되게 삽입고정되며 상기 하측바의 전면에는 전선수용홈이 형성되는 동일형상의 상부틀체 및 하부틀체가 상기 전선수용홈이 서로 마주보도록 맞대어 고정되는 틀체와카본이 도포경화된 카본층이 상기 상부틀체와 하부틀체 사이에 배치되지 않고 외부에 노출되도록 상기 상부틀체와 하부틀체 사이에 삽입고정되는 면상발열체를 포함하여 구성되는 것을 특징으로 하는 면상발열판\n",
            "📑 시작 문장 (raw): <ANY>카본이 도포경화된 카본층이 상기 상부틀체와 하부틀체 사이에 배치되지 않고 외부에 노출되도록 상기 상부틀체와 하부틀체 사이에 삽입고정되는</ANY> <COMPONENT>면상발열체</COMPONENT><RELATION_36>를 포함하여 구성되는</RELATION_36> 것<RELATION_SEP>을 특징으로 하는</RELATION_SEP> <PATEN\n",
            "\n",
            "🔹 Top 4 (score: 0.9934)\n",
            "🆔 특허번호: 1020030023511 | 청구항: 13 (독립항)\n",
            "📄 청구항 전체: 키 톱(key top)을 눌러 신호를 스위칭하는 키 스위칭 장치에 있어서,상호 가위형으로 결합되어 가위 운동을 하는 제1 및 제2 링크 부재상기 링크 부재의 상단에 각각 구비된 한 쌍의 상단 샤프트를 이동 또는 회동 가능하게 수용하는 수용부를 하부에 갖는 키 톱상기 키 톱의 하부에 배치되는 지지판상기 키 톱의 하부에서 상기 지지판상에 배치되며, 접점을 갖는 멤브레인 부재상기 키 톱에 의해 눌러져 일부가 상기 멤브레인의 접점과 접촉하는 절두형 원추 형태의 탄성 스위치상기 지지판과 별체로 형성되며, 상기 링크 부재의 하단에 각각 구비된 한 쌍의 하단 샤프트를 이동 또는 회동 가능하게 고정하는 고정부, 상기 지지판에 고정 체결되는 체결부, 및 상기 탄성 스위치를 그 하부 둘레에서 지지하도록 중앙 개구가 형성된 위치유지수단을 구비하는 장착부재를 포함하는 것을 특징으로 하는 키 스위칭 장치\n",
            "📑 시작 문장 (raw): <ANY>상기 지지판과 별체로 형성되며, 상기 링크 부재의 하단에 각각 구비된 한 쌍의 하단 샤프트를 이동 또는 회동 가능하게 고정하는 고정부, 상기 지지판에 고정 체결되는 체결부, 및 상기 탄성 스위치를 그 하부 둘레에서 지지하도록 중앙 개구가 형성된 위치유지수단</ANY><RELATION_6>을 구비하는</RELATION_6> <COMPONENT>장착부\n",
            "\n",
            "🔹 Top 5 (score: 0.9933)\n",
            "🆔 특허번호: 1019400024294 | 청구항: 2 (종속항)\n",
            "📄 청구항 전체: 제1항에 있어서,상기 체결수단은 중간체와 단열재와 판체를 체결하는 제1볼트와, 중간재와 단열재와 판체를 상, 하부틀에 결착하는제2볼트구성된것을특징으로 하는쉐도우 마스크 금형.\n",
            "📑 시작 문장 (raw): <DIRECTION>제1항에 있어서,</DIRECTION><COMPONENT>상기 체결수단</COMPONENT><ANY>은 중간체와 단열재와 판체를 체결하는 제1볼트와, 중간재와 단열재와 판체를 상, 하부틀에 결착하는</ANY><COMPONENT>제2볼트</COMPONENT><RELATION_015>구성된것을</RELATION_015><RELATION_SE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 최종"
      ],
      "metadata": {
        "id": "FtfXOl_D-Wxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 셀 1: 준비/로드(한 번만 실행) ====\n",
        "from typing import Dict\n",
        "import os, json, re\n",
        "import torch\n",
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from openai import OpenAI\n",
        "\n",
        "# ===== 환경 설정 =====\n",
        "# Colab 런타임 새로 시작하면 반드시 이 셀부터 실행\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# 경로 설정 (Drive 경로 그대로 사용 가능하지만 처음 한 번 /content로 복사하면 I/O 빠릅니다)\n",
        "INDEX_PATH = \"/content/drive/MyDrive/BIG_PROJ/korpat_index_quarter.faiss\"\n",
        "META_PATH  = INDEX_PATH + \".meta.json\"\n",
        "\n",
        "# 성능 최적화를 위해 (선택) 한 번 /content 로 복사\n",
        "# - Drive I/O 느림 → 복사 후 /content/* 로 읽기 권장\n",
        "# - 이미 /content 에 있으면 아래 두 줄은 생략 가능\n",
        "!mkdir -p /content/korpat_index\n",
        "!cp -u \"{INDEX_PATH}\" \"/content/korpat_index/korpat_index.faiss\"\n",
        "!cp -u \"{META_PATH}\"  \"/content/korpat_index/korpat_index.faiss.meta.json\"\n",
        "\n",
        "INDEX_PATH_LOCAL = \"/content/korpat_index/korpat_index.faiss\"\n",
        "META_PATH_LOCAL  = \"/content/korpat_index/korpat_index.faiss.meta.json\"\n",
        "\n",
        "# ===== 디바이스/torch 설정 =====\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cuda.matmul.allow_tf32 = True  # 가능하면 TF32 허용\n",
        "torch.set_float32_matmul_precision(\"high\")    # PyTorch 2.x\n",
        "\n",
        "# ===== KorPat 임베딩 모델/토크나이저 로드 =====\n",
        "MODEL_NAME = \"KIPI-ai/KorPatElectra\"\n",
        "\n",
        "# Electra 계열을 BertModel로 로드하면 경고가 날 수 있습니다.\n",
        "# 해당 체크포인트가 BERT호환 출력(클래스 토큰)만 쓰면 실사용 가능.\n",
        "model = BertModel.from_pretrained(MODEL_NAME, token=ACCESS_TOKEN).to(DEVICE).eval()\n",
        "if DEVICE.type == \"cuda\":\n",
        "    model = model.half()\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, token=ACCESS_TOKEN)\n",
        "\n",
        "# ===== FAISS 인덱스/메타데이터 로드 =====\n",
        "# (선택) 메모리맵으로 읽고 싶으면: faiss.read_index(INDEX_PATH_LOCAL, faiss.IO_FLAG_MMAP)\n",
        "try:\n",
        "    index = faiss.read_index(INDEX_PATH_LOCAL)\n",
        "except TypeError:\n",
        "    # 일부 환경은 IO_FLAG_MMAP 미지원일 수 있어 일반 로드로 대체\n",
        "    index = faiss.read_index(INDEX_PATH_LOCAL)\n",
        "\n",
        "with open(META_PATH_LOCAL, \"r\", encoding=\"utf-8\") as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "print(\"✅ 준비 완료\")\n",
        "print(f\" - DEVICE: {DEVICE}\")\n",
        "print(f\" - index.ntotal: {index.ntotal}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351,
          "referenced_widgets": [
            "52cbe461a2c047e6a0337dac3467ab7f",
            "747d43b8c97944479232478931a2b517",
            "08523de636b0469b81f0637db0b12f5f",
            "bc6c3d37068f45b28319f36dc30ca623",
            "ddcc9d26baf2493f84d579ae563aa325",
            "b3b22f831885402c8da4b415ef888682",
            "337b7a399cf548d185200e8683be1ad0",
            "3aa3f36f7bba4f45be59a606d83cd70b",
            "a5d79e29b38e4b0e9e2a9371f3ca298e",
            "1b35abb33e9047459fe16152807fcb21",
            "19279722eff84824acd7dc5cf552ab88",
            "42ffbbda982549b3b1e82249e534f08f",
            "7e943840ec5e4332be182d4ae97e03e5",
            "77a2b00b09da4a969660e7d9a67e0f02",
            "739fb4780313415aa57afd5984147598",
            "bcb89e9d2d9445d0b8395c4210f671ed",
            "5039614bebce4052a98831d73b3adc86",
            "acaa2f959cd7491d8bac252b56cf94fc",
            "a215486f0ad14143989bc8395c89e6f7",
            "136a2e31c29747b5afbbbb507324262c",
            "8c69857b908d4741b3c92fe78aa86cec",
            "deb9a5816f9240e3b76236a0da8913cb",
            "58c26ac79a0a4085991e21638bc9c2db",
            "fdd6250294884a69b38a8af5e27698e7",
            "0acad9a8b3d44c6f81464d2751b538ad",
            "db31767a609b4fe78216b981b18e1706",
            "7793fc89b59f4242b3c687d25c7409f4",
            "461ab26ffc3e4c7ab1f6eb4d08e829a8",
            "09740d9d8c504985bca48aa0b000cd2a",
            "eda39eb16b0c426084027c9ca232bd2f",
            "6f331b2e50b049b9b94acf062b6c45dc",
            "33502d635258412ab8732b350c4272c8",
            "ce4453e758bb4f3d9370d78d3401a078",
            "31f271714f974ab581005ac34f7bfc27",
            "a81a6b21cec34d528f2f2610a6c4b1a4",
            "7b065ba669c142b3996f91741509189d",
            "6f1ff1f9efb14f02a728c6b626c20462",
            "c503718bb08f46cbb43cd07bb15064ac",
            "0944934bede1457e8d27ff278b36a4a9",
            "4d65716a713c45768ccbfa6673c36819",
            "08867663c7a748feb7590c319b6aab5c",
            "91e0bf148b694eb39e3093c04d95f2b2",
            "4aca50438b084058953b36d1f86c7482",
            "e13ee617fe1a498db1d73223f6c562f7",
            "a4c1d4fdd4424a2390895983388af1f7",
            "fc79d6ca6fae4ed8a07a6e464a40b570",
            "f9dd1c30b0884ecc985eca071b931a5f",
            "c066bf8210d645de8e4690435d87b0cc",
            "c71216f216574f5cb104fbbf873ed48c",
            "260e9e247a074c68b578b817c7d99cbd",
            "af2677d51dd244b59733632d49489118",
            "28f1d235e63d40af8ac2c4e38d7e9071",
            "fbd67d76ac264af582f4276a5ac8d03d",
            "3e60d66792234e7c84438b7ca85b929b",
            "fda857e1c0c14bbe8ce10e760364a456"
          ]
        },
        "id": "E-Wi22nV-YcQ",
        "outputId": "04fd9258-2269-4843-f942-38009ca4d249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52cbe461a2c047e6a0337dac3467ab7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/454M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42ffbbda982549b3b1e82249e534f08f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58c26ac79a0a4085991e21638bc9c2db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/280k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31f271714f974ab581005ac34f7bfc27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4c1d4fdd4424a2390895983388af1f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 준비 완료\n",
            " - DEVICE: cuda\n",
            " - index.ntotal: 1666555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 셀 2: 추론(요청마다 실행) ====\n",
        "import re\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# ✅ 메타데이터 포함 RAG: (app_num, claim_num, text, score)\n",
        "def retrieve_similar_claims_with_meta(query: str, model, tokenizer, index, metadata, device, top_k: int = 5):\n",
        "    import numpy as np\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        inputs = tokenizer(\n",
        "            query,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=256,\n",
        "            return_token_type_ids=False\n",
        "        ).to(device)\n",
        "        vec = model(**inputs).last_hidden_state[:, 0, :]\n",
        "        vec = torch.nn.functional.normalize(vec, p=2, dim=1).cpu().numpy()\n",
        "\n",
        "    scores, indices = index.search(vec, top_k)\n",
        "\n",
        "    # (app_num, claim_num) 단위로 중복 제거 + 원문 구성\n",
        "    seen = set()\n",
        "    results = []\n",
        "    for rank, idx in enumerate(indices[0]):\n",
        "        meta = metadata[idx]\n",
        "        pair = (meta[\"app_num\"], meta[\"claim_num\"])\n",
        "        if pair in seen:\n",
        "            continue\n",
        "        seen.add(pair)\n",
        "\n",
        "        claim_sents = [m for m in metadata if m[\"app_num\"] == pair[0] and m[\"claim_num\"] == pair[1]]\n",
        "        claim_sents.sort(key=lambda x: x[\"sent_num\"])\n",
        "        claim_text = \"\".join(m[\"plain_text\"] for m in claim_sents).strip()\n",
        "\n",
        "        results.append({\n",
        "            \"rank\": rank + 1,\n",
        "            \"score\": float(scores[0][rank]) if isinstance(scores, np.ndarray) else None,\n",
        "            \"app_num\": pair[0],\n",
        "            \"claim_num\": pair[1],\n",
        "            \"text\": claim_text\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# ✅ 호환 래퍼: 예전 코드가 기대한 \"긴 문자열\"을 반환\n",
        "def retrieve_similar_claims(query: str, model, tokenizer, index, metadata, device, top_k: int = 5) -> str:\n",
        "    meta = retrieve_similar_claims_with_meta(query, model, tokenizer, index, metadata, device, top_k)\n",
        "    return \"\\n\\n\".join(item[\"text\"] for item in meta)\n",
        "\n",
        "def generate_patent_specification_from_claim_text(claim_text: str, rag_context) -> dict:\n",
        "    # rag_context가 list(meta)면 텍스트로 변환, str이면 그대로 사용\n",
        "    if isinstance(rag_context, list):\n",
        "        rag_text = \"\\n\\n\".join(item.get(\"text\",\"\") for item in rag_context if isinstance(item, dict))\n",
        "    else:\n",
        "        rag_text = str(rag_context or \"\")\n",
        "\n",
        "    def run_section_agent(title: str, instruction: str, context: str) -> str:\n",
        "        common_instruction = (\n",
        "            \"각 항목은 '…이다/한다'의 현재형 문어체로 작성하고, 줄번호·글머리기호·표 목록을 사용하지 않는다. \"\n",
        "            \"문장은 과장 표현 없이 객관적으로 기술하며, 동일 용어는 처음 정의한 표현을 일관되게 사용하되 각 항목에 중복되는 내용이 들어가지 않도록 주의한다. \"\n",
        "            \"가능한 범위에서는 정량 표현(수치/범위/조건/기준선)을 포함하고, 원인→결과의 인과관계를 명시한다. \"\n",
        "            \"추정·모호어(예: 대략, 상당히, 우수하다)는 금지하며, 항목 간 내용 중복을 피하고 서로 보완적으로 구성한다.\"\n",
        "        )\n",
        "        format_guard = (\n",
        "            \"출력 형식: 아래 JSON 스키마를 정확히 따르고, JSON 이외의 어떤 텍스트(설명/머리말/코드블록 표식)도 포함하지 말 것.\"\n",
        "        )\n",
        "        prompt = f\"\"\"\n",
        "당신은 대한민국 특허 전문 변리사입니다.\n",
        "\n",
        "{common_instruction}\n",
        "\n",
        "{instruction}\n",
        "\n",
        "{format_guard}\n",
        "\n",
        "[입력 질의 또는 초안 요약]\n",
        "{claim_text}\n",
        "\n",
        "[유사 특허 청구항들]\n",
        "{rag_text}\n",
        "\n",
        "[이전 결과(참고 전용)]\n",
        "{context}\n",
        "\"\"\".strip()\n",
        "\n",
        "        # 주의: client 객체는 상위 셀에서 생성되어 있어야 함 (예: OpenAI/PRELIM 설정)\n",
        "        resp = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"당신은 대한민국 특허 전문 변리사입니다.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.5,\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip()\n",
        "\n",
        "    combined_text = f\"\"\"\n",
        "[입력 질의 또는 초안 요약]\n",
        "{claim_text}\n",
        "\n",
        "[유사 특허 청구항들]\n",
        "{rag_text}\n",
        "\"\"\".strip()\n",
        "\n",
        "    # ✅ 섹션 순서 업데이트: 요약은 맨 마지막, 청구항은 앞선 결과를 모두 참고하도록\n",
        "    sections = [\n",
        "        (\n",
        "            \"발명의 명칭\",\n",
        "            \"단일 문자열로 작성한다. 기술 대상을 명확히 하며, 과장·광고성 표현과 불필요한 수식(차세대, 혁신적 등)은 금지한다. \"\n",
        "            \"가능하면 핵심 수단 또는 구성요소를 포함하되, 30자 이내를 권장한다. 줄바꿈 없이 작성한다.\\n\"\n",
        "            'JSON 스키마: {\"발명의 명칭\": \"<텍스트>\"}'\n",
        "        ),\n",
        "        (\n",
        "            \"기술 분야 및 배경 기술\",\n",
        "            \"다음 두 항목을 반드시 해당 문구로 시작하고, 중간에 줄바꿈 없이 **각각 한 문단**으로 작성한다. \"\n",
        "            \"1) '기술 분야:' 200자 이상으로 대상 기술의 분야/적용 대상을 정의한다. \"\n",
        "            \"2) '배경 기술:' [유사 특허 청구항들]을 근거로 종래 방법과 한계(성능·효율·안전·비용·신뢰성·규제)를 400자 이상으로 기술한다. \"\n",
        "            \"해결책 서술은 금지한다.\\n\"\n",
        "            'JSON 스키마: {\"기술 분야\": \"<문단 텍스트>\", \"배경 기술\": \"<문단 텍스트>\"}'\n",
        "        ),\n",
        "        (\n",
        "            \"해결하려는 과제 및 해결 수단\",\n",
        "            \"두 항목을 각각 최소 300자 이상, 줄바꿈 없이 **각각 한 문단**으로 작성한다. \"\n",
        "            \"1) '해결하려는 과제:' 종래 기술의 결함/병목/리스크를 지표나 조건(오차율, 처리량, 전력, 온도 등)과 함께 명시한다. \"\n",
        "            \"2) '과제의 해결 수단:' 핵심 메커니즘·구성요소·상호작용·동작 단계를 기술하고, 과제-수단 대응을 명확히 연결한다. 도면/실시예 번호는 언급 금지.\\n\"\n",
        "            'JSON 스키마: {\"해결하려는 과제\": \"<문단 텍스트>\", \"과제의 해결 수단\": \"<문단 텍스트>\"}'\n",
        "        ),\n",
        "        (\n",
        "            \"발명의 효과\",\n",
        "            \"단일 문단으로 400자 이상 작성한다(문단 번호 불필요). \"\n",
        "            \"핵심 효과(성능·효율·신뢰성·내구·에너지·공정·호환성)와 발생 원인, 적용 조건/범위, 부가 효과(비용 절감, 유지보수, 통합성, 환경/안전)를 포함한다. \"\n",
        "            \"가능하면 비교 기준선(종래 대비 %)이나 범위를 예시하되 과장 금지. 해결 수단 반복은 피하고 효과의 메커니즘과 사용 시나리오 중심으로 정리한다.\\n\"\n",
        "            'JSON 스키마: {\"발명의 효과\": \"<문단 텍스트>\"}'\n",
        "        ),\n",
        "        (\n",
        "            \"청구항\",\n",
        "            \"[이전 결과]의 용어·정의·관계를 그대로 따르고, 새로운 기술요소·용어를 도입하지 않는다. \"\n",
        "            \"[청구항 1], [청구항 2] 형식으로 **가능한 한 많은** 청구항을 작성한다. \"\n",
        "            \"독립항은 발명의 필수 구성요소와 이들 간의 관계를 포괄적으로 규정하되, 기능적 표현만으로 끝내지 말고 구조·수단·동작을 구체적으로 특정한다. \"\n",
        "            \"종속항은 '제 X항에 있어서,'로 시작하며, 상위항의 구성에 추가적인 구성·조건·형태·범위·동작 순서·알고리즘 단계·연결 방식 등을 부가하여 보호범위를 세분화한다. \"\n",
        "            \"효과만 단독으로 기재하는 청구항은 작성하지 않는다. \"\n",
        "            \"각 청구항은 한 문장으로 끝맺고, 선택적 표현(바람직하다/예를 들면/가능하다 등)은 금지한다. \"\n",
        "            \"상대적 표현(얇은/두꺼운/넓은 등)은 기준 또는 수치 범위를 함께 정의한다. 중복 없이 상호 보완적으로 구성한다.\\n\"\n",
        "            'JSON 스키마: {\"청구항\": [\"[청구항 1] ...\", \"[청구항 2] ...\", \"...\"]}'\n",
        "        ),\n",
        "        (\n",
        "            \"요약\",\n",
        "            \"[이전 결과]를 압축적으로 반영하고, 새로운 내용·용어를 추가하지 않는다. 단일 문단 380~450자로 작성한다. \"\n",
        "            \"구성: (1) 기술분야 한줄 → (2) 해결하려는 과제(지표/조건 포함) → (3) 과제의 해결 수단(핵심 메커니즘·구성요소·동작) → \"\n",
        "            \"(4) 발명의 효과(비교 기준선 또는 범위 포함). 동일 용어를 일관되게 사용한다.\\n\"\n",
        "            'JSON 스키마: {\"요약\": \"<문단 텍스트>\"}'\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    spec_parts = {}\n",
        "    context_so_far = combined_text\n",
        "\n",
        "    for title, instruction in sections:\n",
        "        try:\n",
        "            section_out = run_section_agent(title, instruction, context_so_far)\n",
        "        except Exception:\n",
        "            # 실패 시 빈 JSON\n",
        "            if title == \"발명의 명칭\":\n",
        "                section_out = '{\"발명의 명칭\": \"\"}'\n",
        "            elif title == \"기술 분야 및 배경 기술\":\n",
        "                section_out = '{\"기술 분야\": \"\", \"배경 기술\": \"\"}'\n",
        "            elif title == \"해결하려는 과제 및 해결 수단\":\n",
        "                section_out = '{\"해결하려는 과제\": \"\", \"과제의 해결 수단\": \"\"}'\n",
        "            elif title == \"발명의 효과\":\n",
        "                section_out = '{\"발명의 효과\": \"\"}'\n",
        "            elif title == \"청구항\":\n",
        "                section_out = '{\"청구항\": []}'\n",
        "            else:  # 요약\n",
        "                section_out = '{\"요약\": \"\"}'\n",
        "\n",
        "        spec_parts[title] = section_out\n",
        "        context_so_far += f\"\\n\\n[{title} 결과]\\n{section_out}\"\n",
        "\n",
        "    return spec_parts\n",
        "\n",
        "def parse_specification(spec_parts: dict) -> dict:\n",
        "    if not isinstance(spec_parts, dict):\n",
        "        spec_parts = {}\n",
        "\n",
        "    result = {\n",
        "        \"발명의 명칭\": \"\",\n",
        "        \"요약\": \"\",\n",
        "        \"기술 분야\": \"\",\n",
        "        \"배경 기술\": \"\",\n",
        "        \"해결하려는 과제\": \"\",\n",
        "        \"과제의 해결 수단\": \"\",\n",
        "        \"발명의 효과\": \"\",\n",
        "        \"청구항\": \"\"\n",
        "    }\n",
        "\n",
        "    def _safe_load(s: str) -> dict:\n",
        "        if not isinstance(s, str):\n",
        "            return {}\n",
        "        try:\n",
        "            return json.loads(s)\n",
        "        except Exception:\n",
        "            s2 = s.strip()\n",
        "            if s2.startswith(\"```\"):\n",
        "                s2 = s2.strip(\"`\")\n",
        "            l, r = s2.find(\"{\"), s2.rfind(\"}\")\n",
        "            if l != -1 and r != -1 and l < r:\n",
        "                try:\n",
        "                    return json.loads(s2[l:r+1])\n",
        "                except Exception:\n",
        "                    return {}\n",
        "            return {}\n",
        "\n",
        "    # 신규: 발명의 명칭\n",
        "    d = _safe_load(spec_parts.get(\"발명의 명칭\", \"\"))\n",
        "    result[\"발명의 명칭\"] = d.get(\"발명의 명칭\", \"\").strip()\n",
        "\n",
        "    # 기존: 기술 분야/배경 기술\n",
        "    d = _safe_load(spec_parts.get(\"기술 분야 및 배경 기술\", \"\"))\n",
        "    result[\"기술 분야\"] = d.get(\"기술 분야\", \"\").strip()\n",
        "    result[\"배경 기술\"] = d.get(\"배경 기술\", \"\").strip()\n",
        "\n",
        "    # 기존: 과제/해결 수단\n",
        "    d = _safe_load(spec_parts.get(\"해결하려는 과제 및 해결 수단\", \"\"))\n",
        "    result[\"해결하려는 과제\"] = d.get(\"해결하려는 과제\", \"\").strip()\n",
        "    result[\"과제의 해결 수단\"] = d.get(\"과제의 해결 수단\", \"\").strip()\n",
        "\n",
        "    # 기존: 발명의 효과\n",
        "    d = _safe_load(spec_parts.get(\"발명의 효과\", \"\"))\n",
        "    result[\"발명의 효과\"] = d.get(\"발명의 효과\", \"\").strip()\n",
        "\n",
        "    # 청구항\n",
        "    d = _safe_load(spec_parts.get(\"청구항\", \"\"))\n",
        "    claims = d.get(\"청구항\", [])\n",
        "    if isinstance(claims, list):\n",
        "        result[\"청구항\"] = \"\\n\\n\".join([c.strip() for c in claims if isinstance(c, str) and c.strip()])\n",
        "\n",
        "    # 요약(맨 마지막 생성) + 길이 후처리\n",
        "    d = _safe_load(spec_parts.get(\"요약\", \"\"))\n",
        "    raw_summary = d.get(\"요약\", \"\").strip()\n",
        "    result[\"요약\"] = _adjust_summary_length(raw_summary, min_len=380, max_len=450)\n",
        "\n",
        "    return result\n",
        "\n",
        "def _adjust_summary_length(text: str, min_len: int = 380, max_len: int = 450) -> str:\n",
        "    \"\"\"\n",
        "    요약 길이를 400자 언저리로 맞추기 위한 간단한 후처리.\n",
        "    - max_len을 초과하면 문장 경계 기준으로 최대한 자연스럽게 잘라줌.\n",
        "    - min_len보다 짧다면 그대로 둔다(재생성은 모델 프롬프트에서 380~450자로 유도).\n",
        "    \"\"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    n = len(s)\n",
        "    if n <= max_len:\n",
        "        return s\n",
        "    # 문장 경계(마침표/물음표/느낌표/따옴표) 근처에서 컷\n",
        "    cutoff = max_len\n",
        "    # 뒤로 가며 가장 가까운 경계 탐색\n",
        "    for i in range(max_len, max(max_len - 80, min_len) - 1, -1):\n",
        "        if i < len(s) and s[i] in \".?!。！？”’\\\"'…\":\n",
        "            cutoff = i + 1\n",
        "            break\n",
        "    return s[:cutoff].rstrip()\n",
        "\n",
        "# ===== 사용 예시: 여기에 쿼리만 바꿔서 실행 =====\n",
        "# sample_query = \"\"\"\n",
        "# 본원 디자인 “물걸레 브러쉬 청소기”의 하부에는 바닥면을 쓸면서 동시에 닦을 수 있는 본체가 구비되고, 이 본체의 후방에는 밀대 아답터가 결합되어 손으로 밀어서 청소하기 위한 밀대가 회동되게 장착된 형상과 모양의 결합을 디자인의 창작내용의 요점으로 함.\n",
        "# 1. 재질은 합성수지재, 폴리에스테르재, 금속재임.\n",
        "# 2. 본원 디자인 “물걸레 브러쉬 청소기”는 먼지 및 미세이물질을 회전하며 흡입하는 회전브러쉬와 바닥면을 닦아주는 바닥걸레가 구비되어 쓸고 닦기를 동시에 수행 가능한 것임.\n",
        "# \"\"\".strip()\n",
        "\n",
        "# sample_query = \"\"\"\n",
        "# 본 발명은 수술용 로봇 암에 관한 것으로, 특히 수술 부위의 조직을 파지하거나 절단하는 기능을 정밀하고 안정적으로 수행할 수 있는 회동 구조를 갖춘 로봇 암에 관한 것이다. 본 발명에 따른 수술용 로봇 암은 수술 과정에서 사용되는 시술용 그립퍼와 이를 지지 및 회동시키는 메커니즘을 포함한다. 구체적으로, 본 발명은 시술 부위 조직의 파지 및 절단 중 적어도 하나의 기능을 수행하기 위한 시술용 그립퍼와, 상기 그립퍼를 하단에서 고정 지지하는 그립퍼 지지 디스크, 그리고 상기 지지 디스크의 중심 하단부에 연결된 중심바를 포함한다.\n",
        "# 또한, 상기 중심바와 지지 디스크는 볼 조인트에 의해 연결되어, 지지 디스크가 X축 및 Y축 방향으로 자유롭게 회동될 수 있도록 구성된다. 상기 지지 디스크의 중심점을 기준으로 대칭 위치에 배치된 3지점의 둘레면에는 디스크 와이어가 연결되며, 이 디스크 와이어는 각각 하단으로 연장되어 별도의 모터 구동부와 연결된다. 모터 구동부는 상기 와이어를 상하 방향으로 구동함으로써 지지 디스크의 기울기 및 회동 각도를 정밀하게 제어할 수 있으며, 이를 통해 시술용 그립퍼가 원하는 방향으로 정밀하게 조작된다.\n",
        "# 본 발명은 하나의 중심점을 기준으로 2축 회동이 이루어지는 단순하고 안정적인 구조를 채택함으로써, 복잡한 기계적 요소를 줄여 고장 가능성을 낮출 수 있다. 또한, 시술자가 직관적으로 조작할 수 있으며, 유지보수 또한 간편하다는 장점이 있다. 나아가, 와이어 구동 방식을 통해 미세한 제어가 가능하여 실제 수술 시 조직을 섬세하게 파지하거나 원하는 위치에서 정확하게 절단할 수 있어, 기존의 복잡한 로봇 암 구조에 비해 높은 정밀성과 안정성을 제공한다.\n",
        "# 따라서, 본 발명에 따른 수술용 로봇 암은 정밀한 수술 환경에서 안정적이고 효율적인 조작을 가능하게 하며, 장치의 내구성과 경제성 면에서도 우수한 효과를 발휘할 수 있다.\n",
        "# \"\"\".strip()\n",
        "\n",
        "\n",
        "sample_query = \"\"\"\n",
        "초소형 고효율 BLDC 모터를 적용하고 팬의 날개와 하우징 전체를 중공형(中空形) 일체형 카본 복합소재로 설계하여, 내구성은 유지하면서도 무게를 획기적으로 줄인 선풍기. 이를 통해 휴대성을 극대화하고 다양한 거치 형태를 손쉽게 구현할 수 있도록 하여 사용 편의성을 높이는 기술.\n",
        "\"\"\".strip()\n",
        "\n",
        "# ▶︎ 예전 코드와 동일하게 사용해도 됨(문자열 RAG 반환)\n",
        "rag_context = retrieve_similar_claims(\n",
        "    query=sample_query,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    index=index,\n",
        "    metadata=metadata,\n",
        "    device=DEVICE,\n",
        "    top_k=5\n",
        ")\n",
        "\n",
        "print(\"\\n📚 [RAG 검색된 유사 청구항]\\n\")\n",
        "if isinstance(rag_context, str):\n",
        "    print(rag_context[:2000] + (\"\\n...\\n\" if len(rag_context) > 2000 else \"\"))\n",
        "else:\n",
        "    # 혹시 누가 메타 버전을 직접 넘겼다면 안전 출력\n",
        "    preview = \"\\n\\n\".join(item.get(\"text\",\"\") for item in rag_context[:3])\n",
        "    print(preview[:2000] + (\"\\n...\\n\" if len(preview) > 2000 else \"\"))\n",
        "\n",
        "# 아래 주석을 해제해 실행하면 전체 스펙 생성/파싱까지 수행\n",
        "spec_parts = generate_patent_specification_from_claim_text(sample_query, rag_context)\n",
        "parsed = parse_specification(spec_parts)\n",
        "\n",
        "print(\"\\n🔹 발명의 명칭:\", parsed.get(\"발명의 명칭\",\"\"))\n",
        "\n",
        "print(\"\\n🔹 요약\\n\")\n",
        "print(parsed.get(\"요약\",\"\"))\n",
        "\n",
        "for k in [\"기술 분야\",\"배경 기술\",\"해결하려는 과제\",\"과제의 해결 수단\",\"발명의 효과\"]:\n",
        "    v = parsed.get(k,\"\")\n",
        "    preview = v[:800] + (\"\\n...\\n\" if len(v) > 800 else \"\")\n",
        "    print(f\"\\n🔹 {k}\\n{preview}\")\n",
        "\n",
        "print(\"\\n🔹 청구항\\n\")\n",
        "print(parsed.get(\"청구항\",\"\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUvPAnGw-eKl",
        "outputId": "77a23726-da12-4a1d-c901-103bdf7e0d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📚 [RAG 검색된 유사 청구항]\n",
            "\n",
            "제1항 내지 제4항 중 어느 한 항에 있어서,가스가 상기 저장 어셈블리의 내부와 외부 사이를 통과할 수 있도록 상기 링(50)과 케이스(20) 사이 및/또는 링(50)과 덮개(40) 사이에 규정되어 있는적어도하나의가스제거통로를추가포함하는것을특징으로 하는전기 에너지 저장 어셈블리.\n",
            "\n",
            "제 3항에 있어서,장치(200)는;수신상태 감지수단(250)의 감지상태 또는 상기 서브장치(300)로부터의 호출신호를 주기적으로 체크하여 배터리(281)의 전원 온/오프상태를 조절하도록 하는 절전기능을 갖는전원공급수단더포함하는것을특징으로 하는휴대폰의 무선 핸즈프리 시스템.\n",
            "\n",
            "제 4항에 있어서,컨트롤러의 클럭 단자에 엔드 게이트를 연결시키고, 상기 엔드 게이트는 클럭 펄스신호와 충전기 연결 유무 신호를 그 입력으로 하여 휴면(sleep)상태나 서스펜드(suspend) 모드에서 led컨트롤러의전력소모를최소화시키는것을특징으로 하는led를 이용한 배터리 충전 상태 표시장치.\n",
            "\n",
            "제1항에 있어서,쌍의 탄성형 실링부재(30)의 사이를 슬라이딩 이동하는 슬라이더 측면의 전, 후 끝단(221a)(221b)은 유선형으로 경사지게 형성되어, 밀착되는 탄성형 실링부재와의틈새형성억제하도록한것을특징으로 하는리니어 액추에이터의 실링장치.\n",
            "\n",
            "제1항에 있어서,실내조절부(200)에는실내에서 조작할 수 있는 리모콘(18)을 제어기능을 구비하고, 제2송수신부(16)가 그 리모콘 신호를 직접 수신할 수 있도록 하여서 구성되는 수단을 더 포함하는 것을 특징으로 하는 전화선과 무선 인터페이스가능한실내온도조절장치.\n",
            "\n",
            "🔹 발명의 명칭: 초소형 고효율 BLDC 모터를 적용한 중공형 카본 복합소재 선풍기\n",
            "\n",
            "🔹 요약\n",
            "\n",
            "본 발명은 초소형 고효율 BLDC 모터를 이용한 선풍기에 관한 기술로, 팬의 날개와 하우징을 중공형 일체형 카본 복합소재로 설계하여 무게를 약 30% 이상 감소시키면서도 내구성을 유지하는 데 중점을 둔다. 종래 기술의 선풍기는 금속 또는 플라스틱 재질로 제작되어 평균적으로 1.5kg에서 3kg의 무게를 가짐으로써 이동성과 휴대성을 저해하는 문제가 발생한다. 본 발명은 이러한 문제를 해결하기 위해 카본 복합소재의 경량성과 강도를 활용하여 내구성을 유지하면서도 무게를 획기적으로 줄인다. 초소형 BLDC 모터는 전력 소모를 20W 이하로 유지하면서 분당 3000회전 이상의 속도를 제공하여 에너지 효율성을 극대화한다. 이로 인해 선풍기는 사용자의 요구에 맞춰 다양한 거치 형태를 지원할 수 있으며, 휴대성과 사용 편의성을 높이는 효과를 가진다.\n",
            "\n",
            "🔹 기술 분야\n",
            "본 발명은 초소형 고효율 BLDC 모터를 이용한 선풍기에 관한 기술로, 특히 팬의 날개와 하우징을 중공형 일체형 카본 복합소재로 설계하여 무게를 줄이고 내구성을 유지하는 데 중점을 둔다. 이 기술은 가정용, 사무용, 야외용 등 다양한 환경에서 사용될 수 있으며, 휴대성을 높여 사용자에게 편리한 이동성을 제공하는 것을 목표로 한다. 또한, 다양한 거치 형태를 지원하여 사용자 맞춤형 사용이 가능하다.\n",
            "\n",
            "🔹 배경 기술\n",
            "종래의 선풍기는 일반적으로 금속 또는 플라스틱 재질로 제작되어 무게가 상대적으로 무겁고, 이로 인해 휴대성이 저하되는 문제가 있다. 예를 들어, 기존의 팬은 평균적으로 1.5kg에서 3kg의 무게를 가지며, 이는 이동이나 보관 시 불편함을 초래한다. 또한, 금속 재질은 부식이나 마모로 인한 내구성 문제를 안고 있으며, 플라스틱 재질은 열에 약해 변형될 우려가 있다. 따라서, 이러한 재질적 한계로 인해 성능과 효율이 저하되고, 사용자의 안전성 또한 확보하기 어려운 상황이다. 특히, 팬의 설계가 복잡할 경우 제조 비용이 증가하고, 이는 소비자에게 부가적인 비용 부담을 초래한다. 이러한 기술적 한계는 선풍기의 신뢰성과 효율성을 저하시켜 사용자의 만족도를 낮추는 원인이 된다.\n",
            "\n",
            "🔹 해결하려는 과제\n",
            "종래 기술의 선풍기는 일반적으로 금속 또는 플라스틱 재질로 제작되어 무게가 평균 1.5kg에서 3kg에 이르며, 이는 이동성과 휴대성을 저해하는 주요 원인이다. 또한, 이러한 재질은 부식, 마모, 열에 의한 변형 등으로 인해 내구성 문제를 발생시키며, 이는 장기적인 사용 시 성능 저하와 안전성 문제로 이어진다. 특히, 복잡한 설계는 제조 비용을 증가시키고 소비자에게 경제적 부담을 초래한다. 이러한 결함은 사용자가 선풍기를 이동하거나 보관할 때 불편함을 초래하며, 사용자 맞춤형 거치 형태를 구현하는 데 제약을 가한다. 따라서, 종래 기술의 설계와 재질적 한계로 인해 선풍기의 신뢰성과 효율성이 저하되어 사용자의 만족도가 낮아지는 문제가 발생한다.\n",
            "\n",
            "🔹 과제의 해결 수단\n",
            "본 발명은 초소형 고효율 BLDC 모터를 적용하고 팬의 날개와 하우징을 중공형 일체형 카본 복합소재로 설계함으로써, 내구성을 유지하면서도 무게를 획기적으로 감소시키는 기술을 제공한다. 카본 복합소재는 경량성과 높은 강도를 동시에 갖추고 있어, 기존의 금속 및 플라스틱 재질에 비해 약 30% 이상의 무게 감소를 가능하게 한다. 또한, 초소형 BLDC 모터는 전력 소모를 최소화하면서도 높은 처리량을 유지할 수 있어, 에너지 효율성을 극대화한다. 이러한 구성은 팬의 전체적인 구조를 단순화하여 제조 비용을 절감하고, 다양한 거치 형태를 쉽게 구현할 수 있도록 하여 사용자의 편의성을 높인다. 결과적으로, 본 발명은 선풍기의 휴대성을 극대화하고 사용자의 맞춤형 요구를 충족시키는 데 기여한다.\n",
            "\n",
            "🔹 발명의 효과\n",
            "본 발명은 초소형 고효율 BLDC 모터를 적용하고 팬의 날개와 하우징을 중공형 일체형 카본 복합소재로 설계하여 무게를 약 30% 이상 감소시키면서도 내구성을 유지하는 효과를 가진다. 이러한 경량화는 선풍기의 휴대성을 극대화하여 사용자가 다양한 거치 형태를 손쉽게 구현할 수 있도록 하며, 이는 사용 편의성을 높이는 원인이 된다. 카본 복합소재는 높은 강도를 제공하여 내구성을 보장하며, 초소형 BLDC 모터는 에너지 효율성을 극대화하여 전력 소모를 최소화하면서도 높은 성능을 발휘한다. 따라서, 전체 시스템의 신뢰성과 효율성이 향상되어 장기적인 사용 시에도 성능 저하를 방지한다. 이러한 설계는 제조 비용을 절감하고 유지보수의 용이성을 증가시킬 수 있으며, 환경적으로도 긍정적인 영향을 미친다. 종합적으로, 본 발명은 선풍기의 성능과 효율성을 크게 개선하여 사용자 맞춤형 요구를 충족시키는 데 기여한다.\n",
            "\n",
            "🔹 청구항\n",
            "\n",
            "[청구항 1] 초소형 고효율 BLDC 모터와 팬의 날개 및 하우징을 중공형 일체형 카본 복합소재로 구성하여, 내구성을 유지하면서 무게를 약 30% 이상 감소시킨 선풍기.\n",
            "\n",
            "[청구항 2] 제1항에 있어서, 팬의 날개는 공기 흐름을 최적화하기 위해 유선형으로 설계되며, 이로 인해 공기 저항을 최소화하는 것을 특징으로 하는 선풍기.\n",
            "\n",
            "[청구항 3] 제1항에 있어서, 하우징은 경량성을 고려하여 두께가 1mm에서 3mm 범위에 있도록 설계되어, 내구성을 보장하는 것을 특징으로 하는 선풍기.\n",
            "\n",
            "[청구항 4] 제1항에 있어서, 초소형 BLDC 모터는 전력 소모를 20W 이하로 유지하면서도 분당 3000회전 이상의 속도를 제공하는 것을 특징으로 하는 선풍기.\n",
            "\n",
            "[청구항 5] 제1항에 있어서, 선풍기는 다양한 거치 형태를 지원하기 위해 하우징의 하부에 다각형 지지대를 포함하는 것을 특징으로 하는 선풍기.\n",
            "\n",
            "[청구항 6] 제1항에 있어서, 카본 복합소재는 강도와 경량성을 동시에 제공하기 위해 고탄소 섬유와 수지의 복합체로 구성되는 것을 특징으로 하는 선풍기.\n",
            "\n",
            "[청구항 7] 제1항에 있어서, 선풍기는 사용자의 편의성을 높이기 위해 이동형 손잡이를 포함하는 것을 특징으로 하는 선풍기.\n",
            "\n",
            "[청구항 8] 제1항에 있어서, 선풍기는 소음 수준을 30dB 이하로 유지하도록 설계된 소음 저감 구조를 포함하는 것을 특징으로 하는 선풍기.\n",
            "\n",
            "[청구항 9] 제1항에 있어서, 선풍기는 사용자의 요구에 맞춰 풍속을 3단계로 조절할 수 있는 제어 수단을 포함하는 것을 특징으로 하는 선풍기.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== 셀 0: SAFE RESET (port 8000은 kill하지 않음) ====\n",
        "import os, subprocess, signal, time\n",
        "import requests\n",
        "\n",
        "# 우리가 쓰는 자동 포트 후보 (서버 셀과 일치)\n",
        "CANDIDATE_PORTS = [8010, 8080, 9000, 7000]\n",
        "CLOUDFLARED_BIN = \"/content/cloudflared\"\n",
        "NGINX_CONF = \"/content/nginx.conf\"\n",
        "CF_LOG = \"/content/cloudflared.log\"\n",
        "\n",
        "def run(cmd: str) -> str:\n",
        "    return subprocess.run(\n",
        "        cmd, shell=True, check=False,\n",
        "        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True\n",
        "    ).stdout\n",
        "\n",
        "def ports_from_cloudflared_log(log_path=CF_LOG):\n",
        "    # 로그에 \"http://127.0.0.1:PORT\" 형태가 남아있으면 그 포트를 추가로 수집\n",
        "    ports = set()\n",
        "    try:\n",
        "        if os.path.exists(log_path):\n",
        "            txt = open(log_path, \"r\", encoding=\"utf-8\", errors=\"ignore\").read()\n",
        "            import re\n",
        "            for m in re.finditer(r\"http://127\\.0\\.0\\.1:(\\d+)\", txt):\n",
        "                ports.add(int(m.group(1)))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return list(ports)\n",
        "\n",
        "print(\"🧹 Targeted stop (only notebook-started processes) ...\")\n",
        "\n",
        "# 0) ngrok (있다면 종료)\n",
        "out = run(\"ps -ef | grep -v grep | grep 'ngrok' | awk '{print $2}'\")\n",
        "for pid in [p for p in out.strip().splitlines() if p.isdigit()]:\n",
        "    try:\n",
        "        os.kill(int(pid), signal.SIGTERM)\n",
        "        print(f\" - ngrok killed: {pid}\")\n",
        "    except Exception as e:\n",
        "        print(f\" - ngrok skip {pid}: {e}\")\n",
        "\n",
        "# 1) cloudflared (/content/cloudflared로 띄운 것만)\n",
        "out = run(f\"ps -ef | grep -v grep | grep '{CLOUDFLARED_BIN}' | awk '{{print $2}}'\")\n",
        "for pid in [p for p in out.strip().splitlines() if p.isdigit()]:\n",
        "    try:\n",
        "        os.kill(int(pid), signal.SIGTERM)\n",
        "        print(f\" - cloudflared killed: {pid}\")\n",
        "    except Exception as e:\n",
        "        print(f\" - cloudflared skip {pid}: {e}\")\n",
        "\n",
        "# 2) nginx (우리 conf로 뜬 master만)\n",
        "out = run(f\"ps -ef | grep -v grep | grep 'nginx: master process nginx -c {NGINX_CONF}' | awk '{{print $2}}'\")\n",
        "for pid in [p for p in out.strip().splitlines() if p.isdigit()]:\n",
        "    try:\n",
        "        os.kill(int(pid), signal.SIGTERM)\n",
        "        print(f\" - nginx(master) killed: {pid}\")\n",
        "    except Exception as e:\n",
        "        print(f\" - nginx skip {pid}: {e}\")\n",
        "\n",
        "# 3) uvicorn: kill 금지! -> 내부 종료 엔드포인트로만 종료 시도\n",
        "#    서버 코드에 해당 엔드포인트가 없으면 404/연결실패가 나와 자동 스킵됩니다.\n",
        "ports_to_try = list(dict.fromkeys(CANDIDATE_PORTS + ports_from_cloudflared_log()))\n",
        "for port in ports_to_try:\n",
        "    if port == 8000:\n",
        "        continue\n",
        "    url = f\"http://127.0.0.1:{port}/__internal__/shutdown\"\n",
        "    try:\n",
        "        r = requests.post(url, timeout=1.5)\n",
        "        if r.ok:\n",
        "            print(f\" - asked uvicorn on :{port} to shutdown (HTTP {r.status_code})\")\n",
        "            time.sleep(0.7)\n",
        "    except Exception:\n",
        "        # 해당 포트에 우리 서버가 없거나, 엔드포인트가 없으면 무시\n",
        "        pass\n",
        "\n",
        "print(\"🗑️ Removing temp files...\")\n",
        "for p in [NGINX_CONF, CF_LOG]:\n",
        "    try:\n",
        "        if os.path.exists(p):\n",
        "            os.remove(p)\n",
        "            print(f\" - removed {p}\")\n",
        "    except Exception as e:\n",
        "        print(f\" - skip {p}: {e}\")\n",
        "\n",
        "# cloudflared 바이너리는 보존하려면 아래를 주석 처리\n",
        "try:\n",
        "    if os.path.exists(CLOUDFLARED_BIN):\n",
        "        os.remove(CLOUDFLARED_BIN)\n",
        "        print(f\" - removed {CLOUDFLARED_BIN}\")\n",
        "except Exception as e:\n",
        "    print(f\" - skip {CLOUDFLARED_BIN}: {e}\")\n",
        "\n",
        "print(\"✅ SAFE reset done. 모델/인덱스는 메모리에 그대로 남아있습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90c7Df9gBXWz",
        "outputId": "237c1ee8-d4a9-4634-e518-0e6ab12b2c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧹 Targeted stop (only notebook-started processes) ...\n",
            " - cloudflared killed: 50630\n",
            "INFO:     127.0.0.1:52364 - \"POST /__internal__/shutdown HTTP/1.1\" 404 Not Found\n",
            "🗑️ Removing temp files...\n",
            " - removed /content/cloudflared.log\n",
            " - removed /content/cloudflared\n",
            "✅ SAFE reset done. 모델/인덱스는 메모리에 그대로 남아있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!fuser -k 9129/tcp"
      ],
      "metadata": {
        "id": "pwGPEc2-tmNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== FastAPI (Colab용: 포트 9129 고정 + 헬스체크 + 선택적 Cloudflared) ====\n",
        "# 전제: model, tokenizer, index, metadata, DEVICE, client,\n",
        "#       generate_patent_specification_from_claim_text / parse_specification 가 이미 메모리에 있음.\n",
        "\n",
        "!pip -q install fastapi \"uvicorn[standard]\" pydantic==2.* openai==1.* > /dev/null\n",
        "\n",
        "import os, threading, time, subprocess, json, socket\n",
        "from typing import Optional, Dict, Literal\n",
        "from fastapi import FastAPI, Query\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel, Field\n",
        "import requests\n",
        "import uvicorn\n",
        "\n",
        "# ---------- 고정 포트 ----------\n",
        "SERVER_HOST = \"0.0.0.0\"\n",
        "SERVER_PORT = 9129  # << 고정\n",
        "\n",
        "# (안전) 시작 전 해당 포트 점유 프로세스 종료\n",
        "os.system(f\"fuser -k {SERVER_PORT}/tcp >/dev/null 2>&1 || true\")\n",
        "\n",
        "# ---------- 헬스체크 ----------\n",
        "def wait_for_health(port: int, timeout_s: float = 12.0) -> bool:\n",
        "    url = f\"http://127.0.0.1:{port}/health\"\n",
        "    t0 = time.time()\n",
        "    while time.time() - t0 < timeout_s:\n",
        "        try:\n",
        "            r = requests.get(url, timeout=0.7)\n",
        "            if r.ok and r.json().get(\"status\") == \"ok\":\n",
        "                return True\n",
        "        except Exception:\n",
        "            pass\n",
        "        time.sleep(0.25)\n",
        "    return False\n",
        "\n",
        "# ---------- RAG (메타 포함 버전) ----------\n",
        "def retrieve_similar_claims_with_meta(query: str, model, tokenizer, index, metadata, device, top_k: int = 5):\n",
        "    import torch, numpy as np\n",
        "    with torch.inference_mode():\n",
        "        inputs = tokenizer(\n",
        "            query,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=256,\n",
        "            return_token_type_ids=False\n",
        "        ).to(device)\n",
        "        vec = model(**inputs).last_hidden_state[:, 0, :]\n",
        "        vec = torch.nn.functional.normalize(vec, p=2, dim=1).cpu().numpy()\n",
        "\n",
        "    scores, indices = index.search(vec, top_k)\n",
        "\n",
        "    seen = set()\n",
        "    results = []\n",
        "    for rank, idx in enumerate(indices[0]):\n",
        "        meta = metadata[idx]\n",
        "        pair = (meta[\"app_num\"], meta[\"claim_num\"])\n",
        "        if pair in seen:\n",
        "            continue\n",
        "        seen.add(pair)\n",
        "\n",
        "        # 같은 청구항 전체 문장 합치기\n",
        "        claim_sents = [m for m in metadata if m[\"app_num\"] == pair[0] and m[\"claim_num\"] == pair[1]]\n",
        "        claim_sents.sort(key=lambda x: x[\"sent_num\"])\n",
        "        claim_text = \"\".join(m[\"plain_text\"] for m in claim_sents).strip()\n",
        "\n",
        "        results.append({\n",
        "            \"rank\": rank + 1,\n",
        "            \"score\": float(scores[0][rank]) if hasattr(scores, \"__getitem__\") else None,\n",
        "            \"app_num\": pair[0],\n",
        "            \"claim_num\": pair[1],\n",
        "            \"text\": claim_text\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# ---------- FastAPI 앱 ----------\n",
        "app = FastAPI(title=\"KorPat Spec API\", version=\"1.3.0\")\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"], allow_credentials=True, allow_methods=[\"*\"], allow_headers=[\"*\"],\n",
        ")\n",
        "\n",
        "class GenerateRequest(BaseModel):\n",
        "    query: str = Field(..., description=\"명세서 생성을 위한 입력 텍스트(요약/초안/요구사항 등)\")\n",
        "    top_k: Optional[int] = Field(5, ge=1, le=50, description=\"RAG 검색 개수\")\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health():\n",
        "    return {\"status\": \"ok\"}\n",
        "\n",
        "# 내부 종료 엔드포인트 (SAFE RESET에서 사용)\n",
        "server_stop_flag = {\"exit\": False}\n",
        "@app.post(\"/__internal__/shutdown\")\n",
        "def shutdown():\n",
        "    server_stop_flag[\"exit\"] = True\n",
        "    return {\"ok\": True}\n",
        "\n",
        "from fastapi import HTTPException\n",
        "import traceback, sys\n",
        "\n",
        "@app.post(\"/generate\")\n",
        "def generate(\n",
        "    req: GenerateRequest,\n",
        "    minimal: bool = Query(True, description=\"True면 sections_parsed만 반환\"),\n",
        "    include_raw: bool = Query(False, description=\"sections_raw 포함 여부\"),\n",
        "    include_rag_meta: bool = Query(True, description=\"RAG 메타데이터 포함 여부\"),\n",
        "    rag_format: Literal[\"meta\",\"text\"] = Query(\"meta\", description=\"RAG 포맷(meta/text)\")\n",
        ") -> Dict:\n",
        "    # 0) 필수 객체 사전 점검\n",
        "    missing = []\n",
        "    for name in [\"model\",\"tokenizer\",\"index\",\"metadata\",\"DEVICE\",\"client\",\n",
        "                 \"retrieve_similar_claims_with_meta\",\n",
        "                 \"generate_patent_specification_from_claim_text\",\n",
        "                 \"parse_specification\"]:\n",
        "        if name not in globals():\n",
        "            missing.append(name)\n",
        "    if missing:\n",
        "        # 초기화 누락: 바로 알려주기\n",
        "        raise HTTPException(status_code=500, detail={\n",
        "            \"error\": \"Server not initialized\",\n",
        "            \"missing\": missing,\n",
        "            \"hint\": \"셀 1/2에서 모델, 인덱스, 함수들을 먼저 로드하세요.\"\n",
        "        })\n",
        "\n",
        "    try:\n",
        "        # 1) RAG (메타)\n",
        "        rag_meta = retrieve_similar_claims_with_meta(\n",
        "            query=req.query,\n",
        "            model=model, tokenizer=tokenizer, index=index, metadata=metadata, device=DEVICE,\n",
        "            top_k=req.top_k or 5\n",
        "        )\n",
        "        rag_text = \"\\n\\n\".join([item[\"text\"] for item in rag_meta])\n",
        "\n",
        "        # 2) 생성\n",
        "        spec_parts = generate_patent_specification_from_claim_text(req.query, rag_text)\n",
        "\n",
        "        # 3) 파싱\n",
        "        parsed = parse_specification(spec_parts)\n",
        "\n",
        "        # 4) 응답\n",
        "        resp = {\"sections_parsed\": parsed}\n",
        "        if not minimal and include_raw:\n",
        "            resp[\"sections_raw\"] = spec_parts\n",
        "        if include_rag_meta:\n",
        "            resp[\"rag_context\"] = rag_meta if rag_format == \"meta\" else rag_text\n",
        "        return resp\n",
        "\n",
        "    except Exception as e:\n",
        "        # 스택을 JSON으로 돌려줘서 바로 원인 확인\n",
        "        tb = traceback.format_exc()\n",
        "        raise HTTPException(status_code=500, detail={\n",
        "            \"error\": str(e),\n",
        "            \"type\": e.__class__.__name__,\n",
        "            \"traceback\": tb.splitlines()[-20:],  # 마지막 20줄만\n",
        "        })\n",
        "\n",
        "# ---------- Uvicorn 실행 (9129 고정) ----------\n",
        "def _exit_watcher():\n",
        "    import os, signal\n",
        "    while True:\n",
        "        if server_stop_flag.get(\"exit\"):\n",
        "            os.kill(os.getpid(), signal.SIGINT)\n",
        "            break\n",
        "        time.sleep(0.5)\n",
        "\n",
        "def start_uvicorn():\n",
        "    uvicorn.run(app, host=SERVER_HOST, port=SERVER_PORT, log_level=\"info\")\n",
        "\n",
        "th = threading.Thread(target=start_uvicorn, daemon=True)\n",
        "th.start()\n",
        "watcher = threading.Thread(target=_exit_watcher, daemon=True)\n",
        "watcher.start()\n",
        "\n",
        "if wait_for_health(SERVER_PORT):\n",
        "    print(f\"✅ Uvicorn healthy: http://127.0.0.1:{SERVER_PORT}/health\")\n",
        "else:\n",
        "    print(f\"⚠️ Health check failed on port {SERVER_PORT}\")\n",
        "\n",
        "\n",
        "@app.get(\"/debug/deps\")\n",
        "def debug_deps():\n",
        "    deps = {}\n",
        "    for name in [\"model\",\"tokenizer\",\"index\",\"metadata\",\"DEVICE\",\"client\",\n",
        "                 \"retrieve_similar_claims_with_meta\",\n",
        "                 \"generate_patent_specification_from_claim_text\",\n",
        "                 \"parse_specification\"]:\n",
        "        deps[name] = name in globals()\n",
        "    return {\"ok\": all(deps.values()), \"deps\": deps}\n",
        "\n",
        "\n",
        "# ---------- (선택) Cloudflared 터널 ----------\n",
        "USE_CLOUDFLARED = True\n",
        "\n",
        "def ensure_cloudflared(bin_path=\"/content/cloudflared\"):\n",
        "    if os.path.exists(bin_path):\n",
        "        return bin_path\n",
        "    url = \"https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\"\n",
        "    print(\"⬇️  Downloading cloudflared...\")\n",
        "    subprocess.run([\"wget\", \"-q\", \"-O\", bin_path, url], check=True)\n",
        "    os.chmod(bin_path, 0o755)\n",
        "    return bin_path\n",
        "\n",
        "def start_cloudflared(port: int, bin_path=\"/content/cloudflared\"):\n",
        "    # 헬스 통과 확인 후 시작\n",
        "    if not wait_for_health(port, timeout_s=3.0):\n",
        "        print(f\"❌ Health check failed on :{port}. Not starting Cloudflared.\")\n",
        "        return None\n",
        "    # 기존 터널 종료\n",
        "    subprocess.run([\"pkill\", \"-f\", \"cloudflared\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "    time.sleep(0.3)\n",
        "    # URL 추출\n",
        "    log_path = \"/content/cloudflared.log\"\n",
        "    with open(log_path, \"w\") as lf:\n",
        "        _ = subprocess.Popen([bin_path, \"tunnel\", \"--url\", f\"http://127.0.0.1:{port}\"], stdout=lf, stderr=lf)\n",
        "    public_url = None\n",
        "    for _ in range(60):\n",
        "        time.sleep(0.5)\n",
        "        if os.path.exists(log_path):\n",
        "            txt = open(log_path, \"r\").read()\n",
        "            for line in txt.splitlines():\n",
        "                if \"trycloudflare.com\" in line:\n",
        "                    for token in line.split():\n",
        "                        if token.startswith(\"https://\") and \"trycloudflare.com\" in token:\n",
        "                            public_url = token.strip()\n",
        "                            break\n",
        "                if public_url:\n",
        "                    break\n",
        "            if public_url:\n",
        "                break\n",
        "    return public_url\n",
        "\n",
        "public_url = None\n",
        "if USE_CLOUDFLARED and wait_for_health(SERVER_PORT, timeout_s=2.0):\n",
        "    try:\n",
        "        bin_path = ensure_cloudflared()\n",
        "        public_url = start_cloudflared(SERVER_PORT, bin_path)\n",
        "        if public_url:\n",
        "            print(f\"🌍 Public URL (Cloudflared): {public_url}\")\n",
        "            print(f\"   ➤ Health: {public_url}/health\")\n",
        "            print(f\"   ➤ POST   {public_url}/generate\")\n",
        "            print(\"\\n💡 Example usage (parsed-only):\")\n",
        "            print(f\"\"\"curl -s \"{public_url}/generate?minimal=true&include_rag_meta=true&rag_format=meta\" \\\\\n",
        "  -H \"Content-Type: application/json; charset=utf-8\" \\\\\n",
        "  --data-raw '{{\"query\":\"자율주행 차량의 객체 인식 취약점 보완 장치 및 방법\",\"top_k\":5}}'\"\"\")\n",
        "            print(\"\\n💡 Example usage (Windows PowerShell, pretty):\")\n",
        "            print(f\"\"\"$body = @{{ query = \"자율주행 차량의 객체 인식 취약점 보완 장치 및 방법\"; top_k = 5 }} | ConvertTo-Json -Compress\n",
        "Invoke-RestMethod -Uri \"{public_url}/generate?minimal=true&include_rag_meta=true&rag_format=meta\" -Method POST -ContentType \"application/json; charset=utf-8\" -Body $body | ConvertTo-Json -Depth 8\"\"\")\n",
        "        else:\n",
        "            print(\"⚠️ Cloudflared URL을 찾지 못했습니다. /content/cloudflared.log 를 확인하세요.\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Cloudflared 실패: {e}\")\n",
        "\n",
        "print(f\"📍 Local test: http://127.0.0.1:{SERVER_PORT}/health\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y_-F6J8AQG8",
        "outputId": "e9c86ef5-f0f2-4499-b3a0-ef87a372fadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [19286]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:9129 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     127.0.0.1:39240 - \"GET /health HTTP/1.1\" 200 OK\n",
            "✅ Uvicorn healthy: http://127.0.0.1:9129/health\n",
            "INFO:     127.0.0.1:39248 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:39264 - \"GET /health HTTP/1.1\" 200 OK\n",
            "🌍 Public URL (Cloudflared): https://neil-gordon-georgia-thumbnail.trycloudflare.com\n",
            "   ➤ Health: https://neil-gordon-georgia-thumbnail.trycloudflare.com/health\n",
            "   ➤ POST   https://neil-gordon-georgia-thumbnail.trycloudflare.com/generate\n",
            "\n",
            "💡 Example usage (parsed-only):\n",
            "curl -s \"https://neil-gordon-georgia-thumbnail.trycloudflare.com/generate?minimal=true&include_rag_meta=true&rag_format=meta\" \\\n",
            "  -H \"Content-Type: application/json; charset=utf-8\" \\\n",
            "  --data-raw '{\"query\":\"자율주행 차량의 객체 인식 취약점 보완 장치 및 방법\",\"top_k\":5}'\n",
            "\n",
            "💡 Example usage (Windows PowerShell, pretty):\n",
            "$body = @{ query = \"자율주행 차량의 객체 인식 취약점 보완 장치 및 방법\"; top_k = 5 } | ConvertTo-Json -Compress\n",
            "Invoke-RestMethod -Uri \"https://neil-gordon-georgia-thumbnail.trycloudflare.com/generate?minimal=true&include_rag_meta=true&rag_format=meta\" -Method POST -ContentType \"application/json; charset=utf-8\" -Body $body | ConvertTo-Json -Depth 8\n",
            "📍 Local test: http://127.0.0.1:9129/health\n"
          ]
        }
      ]
    }
  ]
}
